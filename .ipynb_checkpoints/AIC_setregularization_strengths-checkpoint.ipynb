{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a763b88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering initiated\n",
      "\n",
      "alpha optimized is: 8.445274503124452 and took 0.9447112083435059 seconds\n",
      "\n",
      "Obtained 28 clusters\n",
      "\n",
      "clustering took: 8.160696506500244 seconds\n",
      "\n",
      "(28, 20)\n",
      "[18.67723285 10.81979179 17.86080945  9.49022124  6.01940764 21.04242414\n",
      "  9.54465679  5.94098321  9.43825088  8.14201765 16.59250913  9.18815985\n",
      "  6.87595065 16.54167368 10.16269841  6.90705944 11.08413972 10.81815906\n",
      " 14.8277356   5.66688693  8.6200363  10.93814815  7.67528554  3.59872107\n",
      "  7.92725617  6.49516227 10.63391837  5.35504014]\n",
      "Initializing W and Z matrices took: 0.07557010650634766 seconds\n",
      "\n",
      "Optimizing W and Z matrices\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-21 19:32:32.601050: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory\n",
      "2022-11-21 19:32:32.601096: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1850] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-11-21 19:32:32.604396: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 new assignment at iteration 49\n",
      "28 old assignment at iteration 49\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 75>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=259'>260</a>\u001b[0m             \u001b[39m# np.savetxt(tmp_dir + \"count_plot/contig_bins_\" + str(i+1) + \"trial\", bins0, delimiter = \",\", fmt=['%d','%f','%d'])\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=260'>261</a>\u001b[0m     \u001b[39m# np.savetxt(tmp_dir + \"count_plot/contig_68448_1209_Zbc_trial\",contig_68448_1209_Zbc, fmt=\"%f\")\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=261'>262</a>\u001b[0m     \u001b[39m# np.savetxt(tmp_dir + \"count_plot/contig_68448_1209_pbc_trial\",contig_68448_1209_pbc, fmt=\"%f\")\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=262'>263</a>\u001b[0m     \u001b[39m# np.savetxt(tmp_dir + \"count_plot/contig_103650_3899_Zbc_trial\",contig_103650_3899_Zbc, fmt=\"%f\")\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=263'>264</a>\u001b[0m     \u001b[39m# np.savetxt(tmp_dir + \"count_plot/contig_103650_3899_pbc_trial\",contig_103650_3899_pbc, fmt=\"%f\")\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=265'>266</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m W, Z\n\u001b[0;32m--> <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=267'>268</a>\u001b[0m W1, Z1 \u001b[39m=\u001b[39m nmf_with_adam(np\u001b[39m.\u001b[39;49mtranspose(W_t), Z_matrix, dat, num_iterations, revert_flag, convergence_criterion, Lw, Lz, Lzp, AIC_check_value)\n\u001b[1;32m    <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=269'>270</a>\u001b[0m \u001b[39m\"\"\" *** END *** \"\"\"\u001b[39;00m\n\u001b[1;32m    <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=271'>272</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mObtained optimized W and Z matrices\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32m/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb Cell 1\u001b[0m in \u001b[0;36mnmf_with_adam\u001b[0;34m(W, Z, X, n, revert_flag, convergence_criterion, Lw, Lz, Lzp, AIC_check_value)\u001b[0m\n\u001b[1;32m    <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=253'>254</a>\u001b[0m         Bz_bc \u001b[39m=\u001b[39m[]\n\u001b[1;32m    <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=254'>255</a>\u001b[0m         \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(np\u001b[39m.\u001b[39mshape(Z)[\u001b[39m1\u001b[39m]):\n\u001b[0;32m--> <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=255'>256</a>\u001b[0m             Bz_bc\u001b[39m.\u001b[39mappend(Z[contig_assign0[f],f])\n\u001b[1;32m    <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=256'>257</a>\u001b[0m         bins0 \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mc_[contig_assign0, np\u001b[39m.\u001b[39marray(Bz_bc)\u001b[39m.\u001b[39mreshape(\u001b[39mlen\u001b[39m(Bz_bc),\u001b[39m1\u001b[39m), np\u001b[39m.\u001b[39marray(contig_names)]\n\u001b[1;32m    <a href='vscode-notebook-cell:/big/work/metadevol/scripts/AIC_setregularization_strengths.ipynb#W0sZmlsZQ%3D%3D?line=257'>258</a>\u001b[0m \u001b[39m#         bins0 = bins0[np.lexsort((bins0[:,1], bins0[:,0]))]\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1351\u001b[0m, in \u001b[0;36m_SliceHelperVar\u001b[0;34m(var, slice_spec)\u001b[0m\n\u001b[1;32m   1308\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_SliceHelperVar\u001b[39m(var, slice_spec):\n\u001b[1;32m   1309\u001b[0m   \u001b[39m\"\"\"Creates a slice helper object given a variable.\u001b[39;00m\n\u001b[1;32m   1310\u001b[0m \n\u001b[1;32m   1311\u001b[0m \u001b[39m  This allows creating a sub-tensor from part of the current contents\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1348\u001b[0m \n\u001b[1;32m   1349\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1351\u001b[0m   \u001b[39mreturn\u001b[39;00m _slice_helper(var\u001b[39m.\u001b[39;49mvalue(), slice_spec, var)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1097\u001b[0m, in \u001b[0;36m_slice_helper\u001b[0;34m(tensor, slice_spec, var)\u001b[0m\n\u001b[1;32m   1095\u001b[0m   var_empty \u001b[39m=\u001b[39m constant([], dtype\u001b[39m=\u001b[39mdtypes\u001b[39m.\u001b[39mint32)\n\u001b[1;32m   1096\u001b[0m   packed_begin \u001b[39m=\u001b[39m packed_end \u001b[39m=\u001b[39m packed_strides \u001b[39m=\u001b[39m var_empty\n\u001b[0;32m-> 1097\u001b[0m \u001b[39mreturn\u001b[39;00m strided_slice(\n\u001b[1;32m   1098\u001b[0m     tensor,\n\u001b[1;32m   1099\u001b[0m     packed_begin,\n\u001b[1;32m   1100\u001b[0m     packed_end,\n\u001b[1;32m   1101\u001b[0m     packed_strides,\n\u001b[1;32m   1102\u001b[0m     begin_mask\u001b[39m=\u001b[39;49mbegin_mask,\n\u001b[1;32m   1103\u001b[0m     end_mask\u001b[39m=\u001b[39;49mend_mask,\n\u001b[1;32m   1104\u001b[0m     shrink_axis_mask\u001b[39m=\u001b[39;49mshrink_axis_mask,\n\u001b[1;32m   1105\u001b[0m     new_axis_mask\u001b[39m=\u001b[39;49mnew_axis_mask,\n\u001b[1;32m   1106\u001b[0m     ellipsis_mask\u001b[39m=\u001b[39;49mellipsis_mask,\n\u001b[1;32m   1107\u001b[0m     var\u001b[39m=\u001b[39;49mvar,\n\u001b[1;32m   1108\u001b[0m     name\u001b[39m=\u001b[39;49mname)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1082\u001b[0m, in \u001b[0;36madd_dispatch_support.<locals>.decorator.<locals>.op_dispatch_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[39m# Fallback dispatch system (dispatch v1):\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1082\u001b[0m   \u001b[39mreturn\u001b[39;00m dispatch_target(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1083\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mTypeError\u001b[39;00m, \u001b[39mValueError\u001b[39;00m):\n\u001b[1;32m   1084\u001b[0m   \u001b[39m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m   \u001b[39m# TypeError, when given unexpected types.  So we need to catch both.\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m   result \u001b[39m=\u001b[39m dispatch(op_dispatch_handler, args, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py:1285\u001b[0m, in \u001b[0;36mstrided_slice\u001b[0;34m(input_, begin, end, strides, begin_mask, end_mask, ellipsis_mask, new_axis_mask, shrink_axis_mask, var, name)\u001b[0m\n\u001b[1;32m   1282\u001b[0m parent_name \u001b[39m=\u001b[39m name\n\u001b[1;32m   1284\u001b[0m \u001b[39mif\u001b[39;00m var \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1285\u001b[0m   \u001b[39mdef\u001b[39;00m \u001b[39massign\u001b[39m(val, name\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m   1286\u001b[0m     \u001b[39m\"\"\"Closure that holds all the arguments to create an assignment.\"\"\"\u001b[39;00m\n\u001b[1;32m   1288\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn import cluster\n",
    "import matplotlib.pyplot as plt\n",
    "from optimize_alpha import optimize_alpha\n",
    "from distance_calculations import distance\n",
    "\n",
    "\n",
    "def initialize_Z(W_t, dat):\n",
    "    \n",
    "    W = np.transpose(W_t)\n",
    "    lmda = 0.1\n",
    "    inverse_term = np.linalg.inv(np.eye(W.shape[0]) + (lmda ** -1) * np.matmul(W,W_t))\n",
    "    woodbury = (lmda ** -1) * np.eye(W.shape[1]) - np.matmul((lmda ** -2) * W_t , np.matmul(inverse_term, W))\n",
    "    print(np.matmul(W_t,dat)[:,11977])\n",
    "    return np.matmul(woodbury, np.matmul(W_t,dat))\n",
    "\n",
    "\n",
    "# def maximize_function(w, z, x, qt):\n",
    "    \n",
    "#     mean = tf.matmul(w, z)\n",
    "#     mean = tf.math.maximum(0.1 * qt * x, 1e-20 + tf.nn.relu(mean))\n",
    "#     W_term = Lw * tf.reduce_sum(tf.abs(w))\n",
    "#     Z_term = Lz * tf.reduce_sum(tf.abs(z))\n",
    "#     block_penalty = Lzp * np.sqrt(sum(lc) / len(lc)) * sum(tf.norm(z / np.sqrt(lc), axis = 1))\n",
    "#     R = - W_term - Z_term - block_penalty\n",
    "#     negative_log_likelihood = - (tf.reduce_sum(- mean + tf.multiply(x, tf.math.log(mean))) + R)\n",
    "#     # negative_log_likelihood = - tf.reduce_sum(- mean + tf.multiply(x, tf.math.log(mean))) \n",
    "        \n",
    "#     return negative_log_likelihood\n",
    "\n",
    "\n",
    "def maximize_regularizedfunction(w, z, x, qt):\n",
    "    mean = tf.matmul(w, z)\n",
    "    mean = tf.math.maximum(0.1 * qt * x, 1e-20 + tf.nn.relu(mean))\n",
    "\n",
    "    \"\"\" L1 norm \"\"\"\n",
    "    W_term = Lw * tf.reduce_sum(tf.abs(w))\n",
    "    Rc = tf.reduce_sum(z, axis=0)\n",
    "    Z_term = Lz * tf.reduce_sum(tf.abs(z)/Rc)\n",
    "\n",
    "    \"\"\" block penalty \"\"\"\n",
    "    W_bterm = Lwp * tf.reduce_sum(tf.norm(w, axis=0))\n",
    "    Z_bterm = Lzp * tf.reduce_sum(tf.norm(z/Rc, axis=1))\n",
    "    R = - W_term - Z_term - W_bterm - Z_bterm\n",
    "\n",
    "    negative_log_likelihood = - (tf.reduce_sum(- mean + tf.multiply(x, tf.math.log(mean))) + R)\n",
    "        \n",
    "    return negative_log_likelihood\n",
    "\n",
    "\n",
    "def optimize_wz(W, Z, X, qt, opt):\n",
    "        \n",
    "    with tf.GradientTape() as tape:\n",
    "        loss = maximize_regularizedfunction(W, Z, X, qt)\n",
    "        LL1.append(loss)\n",
    "    optimized = opt.minimize(loss, [W, Z], tape = tape)\n",
    "    \n",
    "    return optimized\n",
    "\n",
    "\n",
    "def calc_aic(w, z, x, qt):\n",
    "\n",
    "    mean = tf.matmul(w, z)\n",
    "    mean = tf.math.maximum(0.1 * qt * x, 1e-20 + tf.nn.relu(mean))\n",
    "    log_likelihood = tf.reduce_sum(- mean + tf.multiply(x, tf.math.log(mean)))\n",
    "    AIC_score = log_likelihood - tf.math.count_nonzero(tf.nn.relu(w), dtype=\"float64\") - tf.math.count_nonzero(tf.nn.relu(z), dtype=\"float64\")\n",
    "    \n",
    "    return AIC_score\n",
    "\n",
    "\n",
    "s = time.time()\n",
    "if __name__ ==  \"__main__\":\n",
    "    print(\"clustering initiated\"+'\\n')\n",
    "    # tmp_dir = \"/big/work/metadevol/scripts/bamtools_api/build/\"\n",
    "    # tmp_dir = \"/big/work/metadevol/new_simdata/metabat2_bamfiles/\"\n",
    "    tmp_dir = \"/big/work/metadevol/benchmark_dataset1/\"\n",
    "    dat = pd.read_pickle(tmp_dir + 'X_pickle')\n",
    "    # dat = pd.read_hdf(\"/big/work/metadevol/new_simdata/eachsamreads_allcontigs_allalign/coco_correction/X.h5\")\n",
    "    # label = pd.read_csv(tmp_dir + 'contigs_refid_genomeid_withcrossmappeddata', sep =' ', usecols=[0,3], header = None)\n",
    "    label = pd.read_csv(tmp_dir + 'contigs_ids_distindex', sep =' ', header = None)\n",
    "    # dat = pd.read_csv('/big/work/metadevol/count_calc/count_abs', index_col = 0)\n",
    "\n",
    "    lc = label[3]\n",
    "\n",
    "    contig_names = dat.columns\n",
    "    dat = dat.to_numpy()\n",
    "    N, C = np.shape(dat)\n",
    "\n",
    "    Rc    = dat.sum(axis=0)\n",
    "    Rn    = dat.sum(axis=1)\n",
    "\n",
    "    cluster_centers = np.empty((0,N))\n",
    "    cluster_members = []\n",
    "    cluster_members_count = []\n",
    "\n",
    "    s1 = time.time()\n",
    "    a     = optimize_alpha(dat, Rc, Rn, N)\n",
    "    an    = a * Rn / Rn.sum()\n",
    "    alpha = an.sum()\n",
    "\n",
    "    print(\"alpha optimized is:\",a, \"and took\", time.time() - s1, \"seconds\\n\")\n",
    "    \n",
    "    s1 = time.time()\n",
    "    cc = 0\n",
    "    for c in np.arange(C):\n",
    "\n",
    "        best_k = -1\n",
    "\n",
    "        if cluster_centers.size > 0 :\n",
    "\n",
    "            dist = distance(dat[:,c], cluster_centers.T, Rc[c], cluster_centers.sum(axis=1), N, an, alpha)\n",
    "            if (np.min(dist) < 5):\n",
    "                best_k = np.argmin(dist)\n",
    "\n",
    "        if best_k == -1:\n",
    "\n",
    "            cluster_centers = np.vstack((cluster_centers, dat[:,c]))\n",
    "            cluster_members.append([dat[:,c]])\n",
    "            cluster_members_count.append(dat[:,c])\n",
    "            with open(tmp_dir + \"initial_clusters\", \"a\") as f:\n",
    "                f.write(str(contig_names[c]) + \" \" + str(cc) + \"\\n\")\n",
    "            cc = cc + 1 \n",
    "\n",
    "        else:\n",
    "\n",
    "            cluster_members[best_k].append(dat[:,c])\n",
    "            cluster_members_count[best_k] = np.add(cluster_members_count[best_k], dat[:,c])\n",
    "            with open(tmp_dir + \"initial_clusters\", \"a\") as f:\n",
    "                f.write(str(contig_names[c]) + \" \" + str(best_k) + \"\\n\")\n",
    "    \n",
    "    cluster_members_count = np.array(cluster_members_count)\n",
    "    print(\"Obtained {} clusters\".format(len(cluster_centers))+'\\n')\n",
    "    print(\"clustering took:\", time.time()-s1,\"seconds\"+'\\n')\n",
    "\n",
    "    s1 = time.time()\n",
    "    W_t = cluster_members_count/cluster_members_count.sum(axis=1,keepdims=1)\n",
    "    print(np.shape(W_t))\n",
    "    Z_matrix = initialize_Z(W_t, dat)\n",
    "    print(\"Initializing W and Z matrices took:\",time.time()-s1,'seconds\\n')\n",
    "\n",
    "    print(\"Optimizing W and Z matrices\"+'\\n')\n",
    "\n",
    "    s1 = time.time()\n",
    "    \n",
    "\n",
    "    Lw = Lz = 1\n",
    "    Lwp = 2 * Lw\n",
    "    Lzp = 2 * Lw\n",
    "    \n",
    "    AIC_check_value = 0.0\n",
    "\n",
    "    convergence_criterion = 0.001\n",
    "    \n",
    "    revert_flag = 0\n",
    "\n",
    "    num_iterations = 1000\n",
    "\n",
    "    \"\"\" W and Z optimization using SGD with automatic differentiation in Adam \"\"\"\n",
    "\n",
    "    LL1 = []\n",
    "    W_nzcount = []\n",
    "    Z_nzcount = []\n",
    "\n",
    "    # contig_68448_1209_Zbc = []\n",
    "    # contig_68448_1209_pbc = []\n",
    "\n",
    "    # contig_103650_3899_Zbc = []\n",
    "    # contig_103650_3899_pbc = []\n",
    "\n",
    "    def nmf_with_adam(W, Z, X, n, revert_flag, convergence_criterion, Lw, Lz, Lzp, AIC_check_value):\n",
    "        opt = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "        X = tf.convert_to_tensor(X)\n",
    "        X = tf.Variable(X, trainable = False)\n",
    "        W = tf.Variable(W, trainable = True)\n",
    "        Z = tf.Variable(Z, trainable = True)\n",
    "        W_prebest = tf.Variable(W, trainable = False)\n",
    "        Z_prebest = tf.Variable(Z, trainable = False)\n",
    "\n",
    "\n",
    "        # contig_68448_1209_Zbc = []\n",
    "        # contig_68448_1209_pbc = []\n",
    "\n",
    "        # contig_103650_3899_Zbc = []\n",
    "        # contig_103650_3899_pbc = []\n",
    "\n",
    "        for i in range(n):\n",
    "            qt = np.exp(-i/10)\n",
    "            optimize = optimize_wz(W, Z, X, qt, opt)\n",
    "            # if len(LL1) >= 150:\n",
    "            #     if abs((LL1[-1] - LL1[-100])/ LL1[-1]) < convergence_criterion and abs((LL1[-50] - LL1[-150])/ LL1[-50]) < convergence_criterion and revert_flag == 0:\n",
    "            #         AIC_score = calc_aic(W, Z, X, qt)\n",
    "            #         if AIC_score > AIC_check_value:\n",
    "            #             # opt = tf.keras.optimizers.Adam(learning_rate=0.1, beta_1=0.9, beta_2=0.999, epsilon=1e-07)\n",
    "            #             print(AIC_score, \"new AIC is higher than the old one\", AIC_check_value, i+1)\n",
    "            #             Lz = 2 * Lz\n",
    "            #             Lzp = 2 * Lzp\n",
    "            #             W_prebest.assign(W)\n",
    "            #             Z_prebest.assign(Z)\n",
    "            #             AIC_check_value = AIC_score\n",
    "            #             print(W_prebest[0][0], W[0][0], \" is set at\",  i+1)\n",
    "            #             print(Z_prebest[0][0], Z[0][0], \" is set at\",  i+1)\n",
    "            #             # revert_flag = 0\n",
    "\n",
    "            #         else:\n",
    "            #             W.assign(W_prebest)\n",
    "            #             print(\"else condition\", i)\n",
    "            # #             print(W_prebest[0][0], W[0][0], \"iteration \", i)\n",
    "            # #             print(Z_prebest[0][0], Z[0][0], \"iteration before correction\", i)\n",
    "            #             # Z.assign(tf.Variable(initialize_Z(tf.transpose(W), X)))\n",
    "            # #             # print(Z[0][0], \"iteration after correction\", i)\n",
    "            # #             # print(initialize_Z(tf.transpose(W), X))\n",
    "            #             Z.assign(Z_prebest)\n",
    "            #             Lz = Lz / 2\n",
    "            #             Lzp = Lzp / 2\n",
    "            #             revert_flag = 1\n",
    "\n",
    "            #     if revert_flag == 1:\n",
    "            #         if abs((LL1[-1] - LL1[-100])/ LL1[-1]) < convergence_criterion * 0.01 and abs((LL1[-50] - LL1[-150])/ LL1[-50]) < convergence_criterion * 0.01:\n",
    "            #             break\n",
    "\n",
    "            W.assign(tf.nn.relu(W))\n",
    "            W.assign(W / tf.reduce_sum(W, axis = 0))\n",
    "            Z.assign(tf.nn.relu(Z))\n",
    "\n",
    "            W_nzcount.append(tf.math.count_nonzero(W>0.01))\n",
    "            Z_nzcount.append(tf.math.count_nonzero(Z>0.01))\n",
    "\n",
    "\n",
    "            # contig_68448_1209_Zbc.append(Z[:,1209])\n",
    "            # contig_68448_1209_pbc.append((Z/tf.reduce_sum(Z,axis=0))[:,1209])\n",
    "            # contig_103650_3899_Zbc.append(Z[:,3899])\n",
    "            # contig_103650_3899_pbc.append((Z/tf.reduce_sum(Z,axis=0))[:,3899])\n",
    "\n",
    "            if (i+1 == 50 or i+1 == 100 or i+1 == 500 or i+1 == 1000 or i+1 == 9000 or i+1 == 10000):\n",
    "        #     if (i == 9550 or i == 9582):\n",
    "        #         print(np.count_nonzero(W>0.01, axis=0), \"W matrix at iteration\", i)\n",
    "        #         print(np.count_nonzero(Z>0.01, axis=1), \"Z matrix at iteration\", i)\n",
    "        #         np.save(\"/big/work/metadevol/scripts/bamtools_api/build/count_plot/W_matrix_trial\"+ str(i+1), W)\n",
    "        #         np.save(\"/big/work/metadevol/scripts/bamtools_api/build/count_plot/Z_matrix_trial\"+ str(i+1), Z)\n",
    "\n",
    "                Rc_c  = np.sum(Z, axis=0)\n",
    "                pb_c  = Z / Rc_c\n",
    "                cov_b = np.sum(Z, axis=1) / np.sum((np.array(lc) * Z) / Rc_c, axis=1)\n",
    "                # np.savetxt(tmp_dir + \"count_plot/bin_coverage_trial\"+ str(num_iterations),cov_b.reshape(len(cov_b),1), fmt=\"%f\")\n",
    "                pb_min = 0.8 * (cov_b.reshape(len(cov_b),1) * np.sum(np.square(pb_c), axis=0) \\\n",
    "                                / np.sum(cov_b.reshape(len(cov_b),1) * pb_c, axis=0))\n",
    "                pb_min[pb_min > 0.5] = 0.5\n",
    "                contig_assign0 = tf.argmax(pb_c/pb_min, axis=0).numpy()\n",
    "                print(len(set(contig_assign0)), \"new assignment at iteration\", i)\n",
    "                print(len(set(tf.argmax(pb_c, axis=0).numpy())), \"old assignment at iteration\", i)\n",
    "                Bz_bc =[]\n",
    "                for f in range(np.shape(Z)[1]):\n",
    "                    Bz_bc.append(Z[contig_assign0[f],f])\n",
    "                bins0 = np.c_[contig_assign0, np.array(Bz_bc).reshape(len(Bz_bc),1), np.array(contig_names)]\n",
    "        #         bins0 = bins0[np.lexsort((bins0[:,1], bins0[:,0]))]\n",
    "                print(\"Number of total bins \", len(set(bins0[:,0])), \" from new assignment automatic differentiation \\n\")\n",
    "                # np.savetxt(tmp_dir + \"count_plot/contig_bins_\" + str(i+1) + \"trial\", bins0, delimiter = \",\", fmt=['%d','%f','%d'])\n",
    "        # np.savetxt(tmp_dir + \"count_plot/contig_68448_1209_Zbc_trial\",contig_68448_1209_Zbc, fmt=\"%f\")\n",
    "        # np.savetxt(tmp_dir + \"count_plot/contig_68448_1209_pbc_trial\",contig_68448_1209_pbc, fmt=\"%f\")\n",
    "        # np.savetxt(tmp_dir + \"count_plot/contig_103650_3899_Zbc_trial\",contig_103650_3899_Zbc, fmt=\"%f\")\n",
    "        # np.savetxt(tmp_dir + \"count_plot/contig_103650_3899_pbc_trial\",contig_103650_3899_pbc, fmt=\"%f\")\n",
    "\n",
    "        return W, Z\n",
    "\n",
    "    W1, Z1 = nmf_with_adam(np.transpose(W_t), Z_matrix, dat, num_iterations, revert_flag, convergence_criterion, Lw, Lz, Lzp, AIC_check_value)\n",
    "\n",
    "    \"\"\" *** END *** \"\"\"\n",
    "    \n",
    "    print(\"Obtained optimized W and Z matrices\")\n",
    "    \n",
    "    print(\"Optimization took:\", time.time() - s1, \"seconds\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f1dec423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f404e97b520>]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(LL1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0c8e9aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total bins  6  from new assignment automatic differentiation \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#     \"\"\" Assignment of contigs to bins automatic ADAM \"\"\"\n",
    "label = pd.read_csv(tmp_dir + 'contigs_ids', sep =' ', header = None)\n",
    "    # dat = pd.read_csv('/big/work/metadevol/count_calc/count_abs', index_col = 0)\n",
    "    \n",
    "Rc_c  = np.sum(Z1, axis=0)\n",
    "pb_c  = Z1 / Rc_c\n",
    "cov_b = np.sum(Z1, axis=1) / np.sum((np.array(label[3]) * Z1) / Rc_c, axis=1)\n",
    "np.savetxt(tmp_dir + \"bin_coverage0_\"+ str(num_iterations),cov_b.reshape(len(cov_b),1), fmt=\"%f\")\n",
    "pb_min = 0.8 * (cov_b.reshape(len(cov_b),1) * np.sum(np.square(pb_c), axis=0) \\\n",
    "                / np.sum(cov_b.reshape(len(cov_b),1) * pb_c, axis=0))\n",
    "pb_min[pb_min > 0.5] = 0.5\n",
    "contig_assign0 = tf.argmax(pb_c/pb_min, axis=0).numpy()\n",
    "Bz_bc =[]\n",
    "for f in range(np.shape(Z1)[1]):\n",
    "    Bz_bc.append(Z1[contig_assign0[f],f])\n",
    "bins0 = np.c_[contig_assign0, np.array(Bz_bc).reshape(len(Bz_bc),1), np.array(contig_names)]\n",
    "# bins0 = bins0[np.lexsort((bins0[:,1], bins0[:,0]))]\n",
    "print(\"Number of total bins \", len(set(bins0[:,0])), \" from new assignment automatic differentiation \\n\")\n",
    "np.savetxt(tmp_dir + \"contig_bins_\" + str(num_iterations) + \"iter_newadam\", bins0, delimiter = \" \", fmt=['%d','%f','%d'])\n",
    "\n",
    "    \n",
    "#     \"\"\" Assignment of contigs to bins apply gradients \"\"\"\n",
    "    \n",
    "#     Rc_c  = np.sum(Z2, axis=0)\n",
    "#     pb_c  = Z2 / Rc_c\n",
    "#     cov_b = np.sum(Z2, axis=1) / np.sum((np.array(label[3]) * Z2) / Rc_c, axis=1)\n",
    "#     np.savetxt(tmp_dir + \"new_result/bin_coverage1_\"+ str(num_iterations),cov_b.reshape(len(cov_b),1), fmt=\"%f\")\n",
    "#     pb_min = 0.8 * (cov_b.reshape(len(cov_b),1) * np.sum(np.square(pb_c), axis=0) / np.sum(cov_b.reshape(len(cov_b),1) * pb_c, axis=0))\n",
    "#     pb_min[pb_min >2] =2\n",
    "#     contig_assign1 = tf.argmax(pb_c/pb_min, axis=0).numpy()\n",
    "#     Bz_bc =[]\n",
    "#     for f in range(np.shape(Z2)[1]):\n",
    "#         Bz_bc.append(Z2[contig_assign1[f],f])\n",
    "#     bins1 = np.c_[contig_assign1, np.array(Bz_bc).reshape(len(Bz_bc),1), np.array(contig_names)]\n",
    "#     bins1 = bins1[np.lexsort((bins1[:,1], bins1[:,0]))]\n",
    "#     print(\"Number of total bins \", len(set(bins1[:,0])), \" from new assignment apply gradients \\n\")\n",
    "#     np.savetxt(tmp_dir + \"new_result/contig_bins_\" + str(num_iterations) + \"iter_newag\", bins1, delimiter = \",\", fmt=['%d','%f','%s'])\n",
    "    \n",
    "#     contig_assign2 = tf.argmax(Z1/tf.reduce_sum(Z1, axis = 0), axis=0).numpy()\n",
    "#     Bz_bc =[]\n",
    "#     for f in range(np.shape(Z1)[1]):\n",
    "#         Bz_bc.append(Z1[contig_assign2[f],f])\n",
    "#     bins2 = np.c_[contig_assign2, np.array(Bz_bc).reshape(len(Bz_bc),1), np.array(contig_names)]\n",
    "#     bins2 = bins2[np.lexsort((bins2[:,1], bins2[:,0]))]\n",
    "#     print(\"Number of total bins \", len(set(bins2[:,0])), \" from automatic differentiation \\n\")\n",
    "#     np.savetxt(tmp_dir + \"new_result/contig_bins_\" + str(num_iterations) + \"iter_auto\", bins2, delimiter = \",\", fmt=['%d','%f','%s'])\n",
    "\n",
    "#     contig_assign3 = tf.argmax(Z2/tf.reduce_sum(Z2, axis = 0), axis=0).numpy()\n",
    "#     Bz_bc =[]\n",
    "#     for f in range(np.shape(Z2)[1]):\n",
    "#         Bz_bc.append(Z2[contig_assign3[f],f])\n",
    "#     bins3 = np.c_[contig_assign3, np.array(Bz_bc).reshape(len(Bz_bc),1), np.array(contig_names)]\n",
    "#     bins3 = bins3[np.lexsort((bins3[:,1], bins3[:,0]))]\n",
    "#     print(\"Number of total bins \", len(set(bins3[:,0])), \" from apply gradients \\n\")\n",
    "#     np.savetxt(tmp_dir + \"new_result/contig_bins_\" + str(num_iterations) + \"iter_ag\", bins3, delimiter = \",\", fmt=['%d','%f','%s'])\n",
    "\n",
    "#     fig, ax = plt.subplots(1)\n",
    "#     ax[0].plot(LL1, color=\"grey\") # adam\n",
    "#     ax[1].plot(LL2, color=\"r\") # apply gradient\n",
    "#     plt.subplots_adjust(left=0.1,\n",
    "#                         bottom=0.1, \n",
    "#                         right=0.9, \n",
    "#                         top=0.9, \n",
    "#                         wspace=0.4, \n",
    "#                         hspace=0.4)\n",
    "\n",
    "#     plt.savefig(tmp_dir + \"new_result/contig_bins_\" + str(num_iterations) + \"iter.png\",dpt=300,format=\"png\",bbox_inches=\"tight\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f0b3b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1, 2, 3, 4, 5}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(tf.argmax(Z1/tf.reduce_sum(Z1, axis = 0), axis=0).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474047d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.plot(LL1)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"negative log likelihood\")\n",
    "plt.savefig(tmp_dir + \"count_plot/LLplot\" + str(num_iterations) + \"iter.png\",dpt=600,format=\"png\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "568ee361",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(W_nzcount)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"non-zero elements in W (>0.01)\")\n",
    "plt.savefig(tmp_dir + \"count_plot/W_nzcount\" + str(num_iterations) + \"iter.png\",dpt=600,format=\"png\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f13ac3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Z_nzcount)\n",
    "plt.xlabel(\"iterations\")\n",
    "plt.ylabel(\"non-zero elements in Z (>0.01)\")\n",
    "# plt.savefig(tmp_dir + \"count_plot/Z_nzcount\" + str(num_iterations) + \"iter.png\",dpt=600,format=\"png\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1d13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "tmp_dir = \"/big/work/metadevol/scripts/bamtools_api/build/\"\n",
    "xx = np.load(tmp_dir + \"count_plot/W_matrix_trial9551.npy\")\n",
    "xx1 = np.load(tmp_dir + \"count_plot/W_matrix_trial9583.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cb7ad9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01831563888873418"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "math.exp(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e1789",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.load(tmp_dir + \"count_plot/W_matrix_trial9583.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8f71a3c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01831563888873418"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8183cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(tmp_dir + \"count_plot/Z_nzcount20000\",Z_nzcount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15aa8b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(Z_nzcount)\n",
    "# plt.plot(Z_nzcount1)\n",
    "# plt.xlim(10,5000)\n",
    "# plt.ylim(190000, 190200)\n",
    "# plt.savefig(\"/big/work/metadevol/scripts/bamtools_api/build/count_plot/Z_noncount_112_oldreg.png\", dpi=600,format=\"png\",bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7342ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xx = np.loadtxt(\"/big/work/metadevol/scripts/bamtools_api/build/count_plot/W_matrix_112at1000\")\n",
    "xx1 = np.loadtxt(\"/big/work/metadevol/scripts/bamtools_api/build/count_plot/W_matrix_112at5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe56159",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(xx > 0.01, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e49691",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_nzcount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7808569",
   "metadata": {},
   "outputs": [],
   "source": [
    "label[label[0] == 215041]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4241046e",
   "metadata": {},
   "outputs": [],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0c2731",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(cluster_centers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180d545a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
