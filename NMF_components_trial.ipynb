{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0efc1901",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9875280e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering initiated\n",
      "alpha optimized is: 8.440742299720526 and took 1.8392369747161865 seconds\n",
      "\n",
      "distance 16617 [ 317.58276 3726.2012   176.81976 ... 3427.8384   270.10718  803.51074]\n",
      "distance 38278 [ 699.8026  7431.09     326.69336 ... 6096.376    581.94763 1523.3312 ]\n",
      "distance 38780 [ 579.5442  5852.741    242.60696 ... 4714.235    454.28674 1046.0857 ]\n",
      "distance 15570 [3.6858984e+02 4.0388760e+03 1.9171124e+02 ... 1.5061816e+03 2.6598486e+02\n",
      " 6.3196830e-02]\n",
      "distance 14256 [ 312.786   3404.8428   225.97943 ... 2961.395    230.05774  993.09705]\n",
      "distance 35856 [ 402.9358  4165.2524    66.50714 ... 3530.7686   357.2417  1249.8176 ]\n",
      "distance 34004 [ 367.30566 3075.8086   162.10043 ... 2685.3445   280.9181   794.86206]\n",
      "distance 841 [2.2618010e-09 1.1738038e-19 8.3237061e+01 ... 2.3120581e+03 2.0004229e-09\n",
      " 8.7098102e+02]\n",
      "distance 5053 [ 401.45752 2703.8555   144.03824 ... 2394.5261   350.2447   867.53467]\n",
      "distance 37063 [ 399.4889 3177.3347  166.2413 ... 1985.7732  329.7246 1055.4635]\n",
      "distance 20093 [ 385.8932  2547.231    142.79968 ... 2168.4473   332.10675  578.0187 ]\n",
      "distance 889 [3.8738439e-09 9.9641120e-12 7.7394104e+01 ... 2.0947097e+03 1.7309988e-07\n",
      " 8.1937604e+02]\n",
      "distance 15524 [4.3468707e+02 2.8189563e+03 2.2736652e+02 ... 6.0906080e-14 3.4526248e+02\n",
      " 4.7352521e+02]\n",
      "distance 11837 [ 304.0056  2119.0117   134.86246 ... 2636.7207   234.21454  548.0391 ]\n",
      "distance 709 [3.4141578e-04 5.3394531e+01 8.3036255e+01 ... 1.9744082e+03 1.0020074e-01\n",
      " 7.6933514e+02]\n",
      "distance 34364 [ 435.47955 2792.5723   176.70905 ... 2306.2295   380.06793  872.7931 ]\n",
      "distance 40223 [2.8443109e+02 1.4424365e+03 5.1355699e-05 ... 1.6564375e+03 2.5236685e+02\n",
      " 6.6699835e+02]\n",
      "distance 38638 [ 269.36652 1104.5293   109.73776 ...  897.9841   224.54205  454.68967]\n",
      "distance 35380 [252.06548 715.74976 110.22391 ... 883.7538  210.13132 457.91388]\n",
      "distance 12733 [2.5363320e-01 2.8956177e+01 8.6146225e+01 ... 6.3184619e+02 1.8981433e-05\n",
      " 3.8491495e+02]\n",
      "distance 36363 [148.63342  509.062     89.712906 ... 638.4227   127.88806  364.37643 ]\n",
      "distance 32881 [ 96.9447   222.48828   76.1862   ... 605.9237    75.492645 262.39487 ]\n",
      "distance 28247 [117.134155 261.8081   131.95395  ... 530.8833    93.21533  261.391   ]\n",
      "distance 10263 [162.14825  389.65442   75.880875 ... 481.6027   130.57608  283.91113 ]\n",
      "distance 18823 [147.59036 322.7484   70.39909 ... 478.32904 126.10225 307.02917]\n",
      "distance 12425 [ 68.280365 135.99164  113.59997  ... 355.83792   45.344086 243.07684 ]\n",
      "distance 20179 [ 20.348572  37.235657  55.83426  ... 536.5895    24.088287 284.17474 ]\n",
      "distance 5252 [112.39728 211.87311  75.43006 ... 324.793    84.73311 204.94283]\n",
      "distance 32602 [ 83.67232  136.53168   82.024376 ... 286.76068   66.625015 153.59361 ]\n",
      "distance 34253 [127.57151  278.09055   45.427353 ... 349.2977   110.987076 203.26254 ]\n",
      "distance 4328 [3.3078954e-02 8.1972361e+00 4.1596031e+01 ... 2.0336575e+02 6.6377081e-02\n",
      " 1.6058044e+02]\n",
      "distance 19533 [ 78.216736 149.18564   38.00322  ... 192.44922   65.97948  158.5454  ]\n",
      "distance 28987 [ 83.29228 145.74771  57.29177 ... 161.85204  78.63425 131.60712]\n",
      "distance 2171 [20.249298 26.129074 10.871918 ... 58.59675  16.251266 52.370213]\n",
      "distance 41930 [26.561295 35.240555 10.15128  ... 54.7949   26.847763 44.184525]\n",
      "distance 34906 [30.986328 39.066383 25.64207  ... 60.22973  29.59386  43.16913 ]\n",
      "distance 3583 [23.14235  27.37362  23.623913 ... 21.446693 20.109436 23.414055]\n",
      "Obtained 37 clusters from initial clustering\n",
      "Initial clustering took: 2.7157089710235596 seconds\n",
      "distance calculation time: 4.557325839996338 seconds\n",
      "count_numbers_of_sharedcontigs took  0.8919510841369629 seconds\n",
      "find_connected_components took  0.00023865699768066406 seconds\n",
      "number of connected components 22\n",
      "count_by_connecting_centroids took  5.4569175243377686 seconds\n",
      "distance_calculation: 5.457635164260864\n",
      "overall time taken for new clustering is:  5.461215257644653\n",
      "[ 37.5  60.   67.5 ... 158.  265.  216. ] 874\n",
      "0 [2212, 874] 874\n",
      "0 [2212, 874] 874\n",
      "0 1 [5286506.945480904, 5316525.225613808]\n",
      "[ 98.5 212.  119.  ...  79.5  75.   87. ] 1138\n",
      "2 [78, 1136] 1138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yazhini/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [78, 1136] 1138\n",
      "2 0 [2416326.159690858, 2414292.386825543]\n",
      "[145.  146.5 128.5 ... 127.  112.5 145.5] 1583\n",
      "4 [859, 2126] 1583\n",
      "4 [859, 2126] 1583\n",
      "4 0 [3238578.4103596546, 3232883.095063657]\n",
      "[122.5  219.   141.   ... 190.25  74.    98.  ] 899\n",
      "6 [567, 939] 899\n",
      "6 [567, 939] 899\n",
      "6 0 [1663338.2785912915, 1662726.3378422002]\n",
      "[ 242.5  2955.25 3153.   ...  117.5    90.5   203.  ] 164\n",
      "7 [259, 3392] 164\n",
      "[ 242.5  2955.25 3153.   ...  117.5    90.5   203.  ] 164\n",
      "7 [259, 3392, 164] 164\n",
      "7 1 [6321806.277651154, 6360817.001691559, 6352230.854011486]\n",
      "[126.5  76.5  98.  ... 135.   86.  232. ] 2832\n",
      "16 [487, 556] 2832\n",
      "16 [487, 556] 2832\n",
      "16 0 [602947.5195073833, 596051.5745669708]\n",
      "[ 23.         18.5        16.         20.         28.5        19.5\n",
      "  19.         24.5        22.5        35.5        28.         17.5\n",
      "  20.         28.         13.5        24.5        98.         31.\n",
      "  20.5        21.5       157.5        18.         20.        159.\n",
      "  15.5        17.         24.5        13.         40.5        21.\n",
      "  30.5        19.         23.         27.5        23.         50.\n",
      "  19.         23.5        16.5        20.5        20.         38.\n",
      "  20.5        25.5        39.5        66.88892    19.         23.5\n",
      "  21.         27.25       22.         42.         26.5        26.\n",
      "  23.         19.5        17.5        22.         21.5        18.\n",
      "  24.5        65.287728   83.66663    21.25       87.980129   68.5\n",
      "  27.         16.5        57.416694   16.5       102.350493   24.5\n",
      "  23.         23.         32.916674   26.5       111.385572   15.\n",
      "  26.5        16.5        33.5        41.9080614  16.5        33.5\n",
      "  29.5        18.         28.5        21.         28.         32.5\n",
      "  18.         29.5        34.         22.         22.5        24.875004\n",
      "  22.         26.5        20.5        43.5252019  73.7083     30.5\n",
      "  27.5        33.5        21.5        20.5        21.         20.75\n",
      "  22.5        22.5        20.5        34.5        21.5        19.\n",
      "  20.         91.58337    33.         83.1355142  25.5        27.\n",
      "  22.5        25.5        48.         27.5        24.5        23.9031757\n",
      "  18.         29.5        16.5        83.73086    20.         17.\n",
      "  23.         14.5        18.         32.5        17.5        16.\n",
      "  29.         24.5        30.5        24.5        19.5        27.5\n",
      "  18.5        26.5        22.5        20.5        32.         28.5\n",
      "  33.         21.5        24.         52.9442677  27.         21.5\n",
      "  16.         23.5        24.         17.5        86.10837    24.5\n",
      "  29.916678   20.5        26.5        26.         20.         19.\n",
      "  18.5        25.5        19.         54.765926   25.         29.5\n",
      "  25.         18.5        28.0968224  27.         18.5        18.5\n",
      "  22.         18.5        30.         17.         18.         21.\n",
      "  23.1750033  25.5        19.5        16.5        22.         23.\n",
      "  26.5        19.58334    34.58334    33.5        20.         22.5\n",
      "  22.5        19.5        23.5        19.         26.5        16.\n",
      "  22.         18.         35.5        19.5        25.5        19.\n",
      "  19.5        32.         17.5        44.5        20.5982765  23.5\n",
      "  21.5        41.5        35.         37.         18.         22.\n",
      "  19.         36.         28.5        34.         12.         57.684557\n",
      "  61.367041   25.         31.5        17.5        58.25       16.5\n",
      "  73.105089   29.5        16.5        21.5        19.5        22.\n",
      "  18.5        24.         12.5        24.5        26.5        18.5\n",
      "  20.         15.5        19.         52.5        33.25       29.5\n",
      "  27.5        19.         20.5        22.         18.5        17.5\n",
      "  33.5        36.         24.         32.         27.         29.\n",
      "  23.666664   18.         22.         24.         30.5        22.\n",
      "  44.         23.5        26.5        45.8296154  26.5        17.\n",
      "  42.         12.5        28.         15.         30.5        50.5\n",
      "  56.00007    21.         27.5        17.5        60.191707   12.5\n",
      "  30.         40.416697   74.913409   20.         29.5        26.\n",
      "  19.         23.         18.         23.         36.5        24.5\n",
      "  17.         19.         29.350033   21.         19.5        21.\n",
      "  20.         23.         17.         20.5        13.         18.5\n",
      "  19.5        27.         18.5        19.         28.5        22.\n",
      "  69.0284153  19.         21.5        24.5        15.         62.5\n",
      "  74.958297   18.         21.         20.         22.5        23.\n",
      "  17.         17.5        20.5        17.         39.75       17.5\n",
      "  30.5        29.         21.         40.         20.5        27.5\n",
      "  24.         20.         16.         28.         23.5        16.\n",
      "  22.5        46.166708   31.5        28.5        27.         21.5\n",
      "  71.9583     30.5        18.33334    15.         27.5        23.\n",
      "  28.         18.5        43.9960652  33.5        12.5        22.\n",
      "  18.5      ] 23\n",
      "19 [42, 235] 23\n",
      "19 [42, 235] 23\n",
      "19 0 [3531.062882852014, -18574.68944925852]\n",
      "[ 58.    36.    43.    30.5   42.5   40.    26.5   46.5   47.    50.\n",
      "  31.5   42.    40.5   29.5   51.5   34.5   43.    36.    30.5   45.\n",
      "  52.5   38.    55.    34.5   32.    47.5   44.    30.5   50.    37.\n",
      "  45.5   47.    33.    33.5   49.5   35.5   33.    32.5   59.5   28.5\n",
      "  42.5   56.    32.    33.5   40.    55.    39.    33.    20.    48.\n",
      "  43.    40.    48.    75.    45.    38.    34.5   35.5   28.5   40.5\n",
      "  29.    33.5   44.5   30.    36.5   22.    51.    49.5   37.    78.5\n",
      "  55.    38.    50.5   40.    46.5   38.    36.    32.25  43.    35.\n",
      "  40.    42.    36.    60.5   41.5   30.    37.5   31.5   33.5   28.5\n",
      "  25.5   41.5   35.    45.    35.5   32.5   49.   102.    54.    43.5\n",
      "  42.    48.    44.5   42.5   36.    34.5   46.5   41.5   37.5   43.\n",
      "  58.    49.5   39.    33.5   33.    42.5   40.5   46.    33.5  102.75\n",
      "  43.    41.5   44.    40.5   50.5   24.5   41.5   49.5   49.    35.5\n",
      "  32.5   33.5   24.    33.    34.5   37.    39.    29.    46.    52.5\n",
      "  35.    53.5   42.    38.5   38.5   40.    36.5   41.    40.    54.\n",
      " 145.5   38.    52.5   38.5   37.    29.    57.    31.    42.    44.5\n",
      "  35.  ] 150\n",
      "20 [48, 95] 150\n",
      "[ 58.    36.    43.    30.5   42.5   40.    26.5   46.5   47.    50.\n",
      "  31.5   42.    40.5   29.5   51.5   34.5   43.    36.    30.5   45.\n",
      "  52.5   38.    55.    34.5   32.    47.5   44.    30.5   50.    37.\n",
      "  45.5   47.    33.    33.5   49.5   35.5   33.    32.5   59.5   28.5\n",
      "  42.5   56.    32.    33.5   40.    55.    39.    33.    20.    48.\n",
      "  43.    40.    48.    75.    45.    38.    34.5   35.5   28.5   40.5\n",
      "  29.    33.5   44.5   30.    36.5   22.    51.    49.5   37.    78.5\n",
      "  55.    38.    50.5   40.    46.5   38.    36.    32.25  43.    35.\n",
      "  40.    42.    36.    60.5   41.5   30.    37.5   31.5   33.5   28.5\n",
      "  25.5   41.5   35.    45.    35.5   32.5   49.   102.    54.    43.5\n",
      "  42.    48.    44.5   42.5   36.    34.5   46.5   41.5   37.5   43.\n",
      "  58.    49.5   39.    33.5   33.    42.5   40.5   46.    33.5  102.75\n",
      "  43.    41.5   44.    40.5   50.5   24.5   41.5   49.5   49.    35.5\n",
      "  32.5   33.5   24.    33.    34.5   37.    39.    29.    46.    52.5\n",
      "  35.    53.5   42.    38.5   38.5   40.    36.5   41.    40.    54.\n",
      " 145.5   38.    52.5   38.5   37.    29.    57.    31.    42.    44.5\n",
      "  35.  ] 150\n",
      "20 [48, 95, 48] 150\n",
      "20 0 [3345.0549543097595, -6097.865007152373, -6266.580504207908]\n",
      "[ 30.    33.5   35.    43.5   32.    45.    34.    18.5   23.5   25.5\n",
      "  28.5   80.5   27.5   39.    35.5   31.    23.    26.5   34.    29.\n",
      "  30.5   22.    26.5   24.5   38.5   56.    43.    26.5   28.5   26.5\n",
      "  34.    28.    30.    35.    28.    44.5   23.5   24.5   29.5   33.5\n",
      "  29.    41.5   60.5   35.5   28.5   38.5   28.    31.    38.5   30.\n",
      "  22.5   30.    25.    31.5   23.5   44.    28.    58.    29.5   27.\n",
      "  37.5   32.5   16.    26.5   26.5   28.5   33.    26.5   45.    43.5\n",
      "  20.5   29.5   33.    40.5   32.    26.5   25.5   25.    22.5   46.5\n",
      "  25.5   23.    31.    43.5   43.5   72.25  30.5   46.5   23.    27.5\n",
      "  33.    21.5   22.5   41.    31.5   28.5   31.    29.5   53.5   31.5\n",
      "  43.5   38.    26.5   44.5   31.    34.5   28.    61.5   23.5   22.\n",
      "  32.    29.    22.    29.5   35.5   25.5   39.    21.    24.    34.5\n",
      "  34.    24.    31.5   34.    28.5   23.    32.5   29.    28.5   27.5\n",
      "  44.5   34.5   39.    30.5   26.5   24.5   82.    33.5   28.5   21.\n",
      "  55.5   30.    44.5   40.5   26.5   30.5   32.5   27.5   29.5   36.\n",
      "  37.    31.    25.5   36.5   29.    77.75  20.    30.    28.    32.5\n",
      "  27.    18.   104.5   22.5   23.5   22.5   39.    57.    34.    21.5\n",
      "  30.5   32.5   23.5   24.    33.5   29.5   41.    28.5   44.5   41.5\n",
      "  19.5   20.5   26.    22.5   29.    28.5   42.5   35.5   34.5   38.\n",
      "  25.    29.    31.    30.5   24.    28.    23.    33.    34.    34.5\n",
      "  49.5   38.    33.5   27.    36.    32.5   24.5   84.5   46.5   25.5\n",
      "  24.    26.5   20.5   29.    31.5   28.5   34.    26.    26.    27.5\n",
      "  40.5   27.5   47.    43.5   28.    28.    52.5   24.5   40.    26.5\n",
      "  32.5   27.5   28.    22.5   20.    37.5   27.    37.5   24.5   35.5\n",
      "  27.    39.    42.    33.    28.    20.5   33.5   26.5   27.    34.\n",
      "  30.5   19.5   37.    41.5   31.5   29.5   27.    19.5   23.5   32.\n",
      "  27.5   44.    40.    31.    32.    26.5   44.5   25.5   33.5   36.5\n",
      "  56.    28.5   30.5   34.    50.    17.5   31.5   32.5   15.5   27.\n",
      "  31.5   34.5   34.5   21.    27.5   29.5   25.5   30.5   31.5   28.\n",
      "  37.    41.5   27.    29.5   26.5   28.    28.  ] 162\n",
      "21 [292, 5] 162\n",
      "21 [292, 5] 162\n",
      "21 0 [556.8099222827568, -2849.1650819208953]\n",
      "(20, 24)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from optimize_parameters import optimize_alpha\n",
    "from distance_calculations_source import distance\n",
    "from new_clustering_algorithm import cluster_by_connecting_centroids\n",
    "\n",
    "def np_relu(x):\n",
    "    \n",
    "    return np.maximum(0,x)\n",
    "\n",
    "\n",
    "def initialize_Z(W, dat):\n",
    "    \n",
    "    W_t = np.transpose(W)\n",
    "    lmda = 0.1\n",
    "    inverse_term = np.linalg.inv(np.eye(W.shape[0]) + (lmda ** -1) * np.matmul(W,W_t))\n",
    "    woodbury = (lmda ** -1) * np.eye(W.shape[1]) - np.matmul((lmda ** -2) * W_t , np.matmul(inverse_term, W))\n",
    "    Z = np_relu(np.matmul(woodbury, np.matmul(W_t,dat)))\n",
    "    \n",
    "    return Z\n",
    "\n",
    "\n",
    "def maximize_function(w, z, x):\n",
    "    \n",
    "    mean = np.matmul(w, z)\n",
    "    mean = 1e-10 + np_relu(mean)\n",
    "    negative_log_likelihood = np.sum(- mean + np.multiply(x, np.log(mean)))\n",
    "\n",
    "    return negative_log_likelihood\n",
    "\n",
    "\n",
    "def calc_aic(w, z, x):\n",
    "\n",
    "    mean = np.matmul(w, z)\n",
    "    mean = 1e-10 + np_relu(mean)\n",
    "    log_likelihood = np.sum(- mean + np.multiply(x, np.log(mean)))\n",
    "    # print('differences', np.count_nonzero(np_relu(w) > 1e-05) - np.count_nonzero(np_relu(z) > 1e-05))\n",
    "    AIC = log_likelihood - np.count_nonzero(np_relu(w) > 1e-05) - np.count_nonzero(np_relu(z) > 1e-05)\n",
    "    \n",
    "    return AIC\n",
    "\n",
    "\n",
    "\"\"\" Multiplicative Updates \"\"\"\n",
    "\n",
    "def multiplicative_updates(W, Z, X, n, method):\n",
    "    \n",
    "    lw = 0.0\n",
    "    lz = 1e-01\n",
    "    beta = 0.5\n",
    "    convergence_criteria = 0.0001\n",
    "    epsilon_reg = 1e-05\n",
    "    loss_values = []\n",
    "    \n",
    "    global AIC\n",
    "    \n",
    "    if method == 0:\n",
    "        \n",
    "        for i in range(n):\n",
    "\n",
    "            mean = np.matmul(W, Z)\n",
    "            mean = 1e-10 + np_relu(mean)\n",
    "            X_by_mean = X / mean\n",
    "\n",
    "            W = np.multiply(W, np_relu(np.matmul(X_by_mean, np.transpose(Z))))\n",
    "            W = W / np.sum(W, axis = 0)\n",
    "            Z = np.multiply(Z, np_relu(np.matmul(np.transpose(W), X_by_mean)))\n",
    "\n",
    "            loss_values.append(maximize_function(W, Z, X))\n",
    "            \n",
    "            if len(loss_values) >= 10 :\n",
    "                \n",
    "                if ((loss_values[i] - loss_values[i-10]) / loss_values[i]) < convergence_criteria:\n",
    "                    AIC = calc_aic(W, Z, X)\n",
    "                    # print(\"Function is converged\")\n",
    "                    break\n",
    "        return  W, Z, loss_values, AIC\n",
    "    \n",
    "    \n",
    "    if method == 1:\n",
    "        \n",
    "        for i in range(n):\n",
    "\n",
    "            mean = np.matmul(W, Z)\n",
    "            mean = 1e-10 + np_relu(mean)\n",
    "            X_by_mean = X / mean\n",
    "\n",
    "            Z_reg =  (lz * beta) / np.power(np.abs(Z+epsilon_reg), 1-beta)\n",
    "            Z = np.multiply(Z, np_relu(np.matmul(np.transpose(W), X_by_mean) - Z_reg))\n",
    "            \n",
    "            loss_values.append(maximize_function(W, Z, X))\n",
    "\n",
    "            if len(loss_values) >= 10 :\n",
    "                if ((loss_values[i] - loss_values[i-10]) / loss_values[i]) < convergence_criteria:\n",
    "                    AIC = calc_aic(W, Z, X)\n",
    "                    # print(\"Function is converged\")\n",
    "                    break\n",
    "                \n",
    "        return  Z, loss_values, AIC\n",
    "    \n",
    "    \n",
    "    if method == 2:\n",
    "        \n",
    "        for i in range(n):\n",
    "\n",
    "            mean = np.matmul(W, Z)\n",
    "            mean = 1e-10 + np_relu(mean)\n",
    "            X_by_mean = X / mean\n",
    "\n",
    "            W_reg =  (lw * beta) / np.power(np.abs(W+epsilon_reg), 1-beta)\n",
    "            Z_reg =  (lz * beta) / np.power(np.abs(Z+epsilon_reg), 1-beta)\n",
    "\n",
    "            W = np.multiply(W, np_relu(np.matmul(X_by_mean, np.transpose(Z)) - W_reg))\n",
    "            W = W / np.sum(W, axis = 0) \n",
    "            Z = np.multiply(Z, np_relu(np.matmul(np.transpose(W), X_by_mean) - Z_reg))\n",
    "\n",
    "            loss_values.append(maximize_function(W, Z, X))\n",
    "\n",
    "            # if len(loss_values) >= 10 :\n",
    "            #     if ((loss_values[i] - loss_values[i-10]) / loss_values[i]) < convergence_criteria:\n",
    "            #         AIC = calc_aic(W, Z, X)\n",
    "            #         # print(\"Function is converged\")\n",
    "            #         break\n",
    "                \n",
    "        return  W, Z, loss_values, AIC\n",
    "\n",
    "    \n",
    "\"\"\" End multiplicative updates \"\"\"\n",
    "                               \n",
    "                                \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    s = time.time()\n",
    "    print(\"clustering initiated\")\n",
    "    tmp_dir = \"/big/work/metadevol/benchmark_dataset1/\"\n",
    "    # tmp_dir = \"/big/work/metadevol/scripts/bamtools_api/build/\"\n",
    "    dat = pd.read_pickle(tmp_dir + 'X_pickle')\n",
    "    contig_names = dat.columns\n",
    "    d0 = 1\n",
    "    min_shared_contigs = 5\n",
    "    s_start = time.time()\n",
    "    clusters, numclust_incomponents, an, alpha, N = cluster_by_connecting_centroids(dat, d0, min_shared_contigs)\n",
    "    print(\"distance_calculation:\", time.time() - s_start)\n",
    "    print(\"overall time taken for new clustering is: \", time.time()-s)\n",
    "    \n",
    "    label = pd.read_csv(tmp_dir + 'contigs_ids_distindex', sep =' ', header = None)\n",
    "    # label = pd.read_csv(tmp_dir + 'contigs_refid_genomeid_withcrossmappeddata', sep =' ', header = None)\n",
    "    lc = np.array(label[3])\n",
    "    \n",
    "    dat = dat.to_numpy()\n",
    "   \n",
    "    num_iterations = 100\n",
    "    \n",
    "    W_full = []\n",
    "    Z_zbc_lcov = []\n",
    "    epsilon = 1e-10\n",
    "\n",
    "\n",
    "    for k in np.arange(len(numclust_incomponents)):\n",
    "\n",
    "        if numclust_incomponents[k] > 1 :\n",
    "            dat_s = dat[:, clusters[k]]\n",
    "            lc_s = lc[clusters[k]]\n",
    "            Rc_s = dat_s.sum(axis = 0)\n",
    "            AIC_score = []\n",
    "            \n",
    "            optimized = {}\n",
    "            \n",
    "            LL_values = {}\n",
    "            \n",
    "            for _ in range(3):\n",
    "                \n",
    "                trial_bval = _\n",
    "                k_contigs = []\n",
    "\n",
    "                if trial_bval == 0:\n",
    "                    k_contigs = dat_s.sum(axis=1) + epsilon\n",
    "                    k_contigs = k_contigs.reshape(N,1)\n",
    "\n",
    "                else:\n",
    "                    if trial_bval + 1 <= numclust_incomponents[k]: \n",
    "\n",
    "                        ind = []\n",
    "\n",
    "                        for i in range(trial_bval+1):\n",
    "\n",
    "                            if i == 0:\n",
    "\n",
    "                                c0_ind = np.argmax(dat_s.sum(axis=0))\n",
    "                                print(dat_s.sum(axis=0), c0_ind)\n",
    "                                c0 = dat_s[:, [c0_ind]]\n",
    "                                dist = distance(c0, dat_s, Rc_s[c0_ind], Rc_s, N, an, alpha)\n",
    "                                c_ind = np.argmax(dist)\n",
    "                                c = dat_s[:, [c_ind]]\n",
    "                                k_contigs = c\n",
    "                                ind.append(c_ind)\n",
    "\n",
    "                            else:\n",
    "\n",
    "                                dist_sum = []\n",
    "\n",
    "                                for f in range(np.shape(k_contigs)[1]):\n",
    "                                    dist_sum.append(distance(k_contigs[:,[f]],dat_s, Rc_s[ind[f]], Rc_s, N, an, alpha))\n",
    "                                # print('distance', np.shape(np.array(dist_sum)),  np.max(np.array(dist_sum)), np.array(dist_sum).sum(axis=0))\n",
    "                                f_ind = np.argmax(np.array(dist_sum).sum(axis=0))\n",
    "                                ind.append(f_ind)\n",
    "                                k_contigs = np.hstack((k_contigs, dat_s[:, [f_ind]])) \n",
    "                    print(k, ind, c0_ind)\n",
    "                W = np.array(k_contigs) \n",
    "                \n",
    "                W_norm = W / W.sum(axis = 0)\n",
    "            \n",
    "                if not np.shape(W)[0] == 0:\n",
    "                    \n",
    "                    Z = initialize_Z(W_norm, dat_s)\n",
    "\n",
    "                    W_opt, Z_opt, LL, AIC = multiplicative_updates(W_norm, Z, dat_s, num_iterations, 0)\n",
    "                    optimized[\"W\"+str(trial_bval)] = W_opt\n",
    "                    optimized[\"Z\"+str(trial_bval)] = Z_opt\n",
    "                    AIC_score.append(AIC)\n",
    "                    LL_values[str(trial_bval)] = LL\n",
    "\n",
    "            # obtain best k using maximum AIC value    \n",
    "            bval = np.argmax(AIC_score)\n",
    "            print(k, bval, AIC_score)\n",
    "            W_full.append(optimized[\"W\"+str(bval)])\n",
    "            # z_bc = optimized[\"Z\"+str(bval)]\n",
    "            # weights = (optimized[\"Z\"+str(bval)] ** 5) / (Rc_s ** 4)\n",
    "            # weights_summedoverC = np.sum(weights, axis=1, keepdims = True)\n",
    "            # small_cov_b = np.sum((weights * (z_bc / lc_s) / weights_summedoverC), axis=1, keepdims=True)\n",
    "            # z_bc_corrected = z_bc/(lc_s * small_cov_b)\n",
    "            # Z_zbc_lcov.append(z_bc_corrected)\n",
    "            # zbcsum_value = np.sum(z_bc_corrected, axis=0)\n",
    "            # print(k, np.min(zbcsum_value), np.max(zbcsum_value))\n",
    "            # if k == 21:\n",
    "            #     print(z_bc_corrected[:,np.nonzero(clusters[k] == 41399)])\n",
    "\n",
    "        else:\n",
    "\n",
    "            dat_s = dat[:, clusters[k]].sum(axis=1) + epsilon\n",
    "            dat_s = dat_s.reshape(N,1) \n",
    "            dat_s = dat_s / dat_s.sum() # not resulting in 1.0 (eg., 0.9999999999999998, 1.0000000000000002)\n",
    "            W_full.append(dat_s)\n",
    "            # z_bc = initialize_Z(dat_s, dat_s)\n",
    "            # weights = (z_bc ** 5) / (Rc_s ** 4)\n",
    "            # weights_summedoverC = np.sum(weights, axis=1, keepdims = True)\n",
    "            # small_cov_b = np.sum((weights * (z_bc / lc_s) / weights_summedoverC), axis=1, keepdims=True)\n",
    "            # Z_zbc_lcov.append(z_bc/(lc_s * small_cov_b))\n",
    "\n",
    "    W_full = np.concatenate(W_full, axis = 1)\n",
    "    # Z_zbc_lcov = np.concatenate(Z_zbc_lcov, axis = 0)\n",
    "    print(np.shape(W_full))\n",
    "\n",
    "    Z = initialize_Z(W_full, dat)\n",
    "    \n",
    "    # LL.append(maximize_function(W_full, Z, dat))\n",
    "\n",
    "    Z_full, LL, AIC_score = multiplicative_updates(W_full, Z, dat, num_iterations, 1)\n",
    "    # LL.append(LL_values)\n",
    "    \n",
    "    # plt.plot(LL)\n",
    "    # W_fullopt, Z_fullopt, LL, AIC_final = multiplicative_updates(W_full, Z_full, dat, num_iterations, 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # \"\"\" Assignment \"\"\"\n",
    "    # Z_assign = Z_full\n",
    "    # Rc_c  = np.sum(Z_assign, axis=0)\n",
    "    # pb_c  = Z_assign / Rc_c\n",
    "    # cov_b = np.sum(Z_assign, axis=1) / np.sum((np.array(lc) * Z_assign) / Rc_c, axis=1)\n",
    "    # pb_min = 0.8 * (cov_b.reshape(len(cov_b),1) * np.sum(np.square(pb_c), axis=0) \\\n",
    "    #                 / np.sum(cov_b.reshape(len(cov_b),1) * pb_c, axis=0))\n",
    "    # pb_min[pb_min > 0.5] = 0.5\n",
    "    # contig_assign0 = np.argmax(pb_c/pb_min, axis=0)\n",
    "    \n",
    "    # print(len(set(contig_assign0)), \"number of bins\")\n",
    "    # print(len(set(np.argmax(Z_assign, axis=0))), \"just max\")\n",
    "\n",
    "\n",
    "    # \"\"\" New assignment - more than one bins for contigs is possible\"\"\"\n",
    "    Z_assign = Z_full\n",
    "    Rc_c  = np.sum(Z_assign, axis=0)\n",
    "    pb_c  = np.power(Z_assign/Rc_c,4)\n",
    "    Z_l = Z_assign / np.array(lc)\n",
    "\n",
    "    cov_b = (np.multiply(pb_c,Z_l).sum(axis=1)) / pb_c.sum(axis=1)\n",
    "\n",
    "    pi_bc1 = Z_assign / np.row_stack(cov_b)\n",
    "    pi_bc2 = pi_bc1.sum(axis=0)\n",
    "\n",
    "    pi_bc = pi_bc1 / pi_bc2\n",
    "\n",
    "    np.argwhere(pi_bc>0.2)\n",
    "    # np.savetxt(tmp_dir + \"indices_pibc_bins\",np.argwhere(pi_bc>0.2), fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcd2a999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering initiated\n",
      "alpha optimized is: 8.440742299720526 and took 1.703038215637207 seconds\n",
      "\n",
      "distance 16617 [ 317.58276 3726.2012   176.81976 ... 3427.8384   270.10718  803.51074]\n",
      "distance 38278 [ 699.8026  7431.09     326.69336 ... 6096.376    581.94763 1523.3312 ]\n",
      "distance 38780 [ 579.5442  5852.741    242.60696 ... 4714.235    454.28674 1046.0857 ]\n",
      "distance 15570 [3.6858984e+02 4.0388760e+03 1.9171124e+02 ... 1.5061816e+03 2.6598486e+02\n",
      " 6.3196830e-02]\n",
      "distance 14256 [ 312.786   3404.8428   225.97943 ... 2961.395    230.05774  993.09705]\n",
      "distance 35856 [ 402.9358  4165.2524    66.50714 ... 3530.7686   357.2417  1249.8176 ]\n",
      "distance 34004 [ 367.30566 3075.8086   162.10043 ... 2685.3445   280.9181   794.86206]\n",
      "distance 841 [2.2618010e-09 1.1738038e-19 8.3237061e+01 ... 2.3120581e+03 2.0004229e-09\n",
      " 8.7098102e+02]\n",
      "distance 5053 [ 401.45752 2703.8555   144.03824 ... 2394.5261   350.2447   867.53467]\n",
      "distance 37063 [ 399.4889 3177.3347  166.2413 ... 1985.7732  329.7246 1055.4635]\n",
      "distance 20093 [ 385.8932  2547.231    142.79968 ... 2168.4473   332.10675  578.0187 ]\n",
      "distance 889 [3.8738439e-09 9.9641120e-12 7.7394104e+01 ... 2.0947097e+03 1.7309988e-07\n",
      " 8.1937604e+02]\n",
      "distance 15524 [4.3468707e+02 2.8189563e+03 2.2736652e+02 ... 6.0906080e-14 3.4526248e+02\n",
      " 4.7352521e+02]\n",
      "distance 11837 [ 304.0056  2119.0117   134.86246 ... 2636.7207   234.21454  548.0391 ]\n",
      "distance 709 [3.4141578e-04 5.3394531e+01 8.3036255e+01 ... 1.9744082e+03 1.0020074e-01\n",
      " 7.6933514e+02]\n",
      "distance 34364 [ 435.47955 2792.5723   176.70905 ... 2306.2295   380.06793  872.7931 ]\n",
      "distance 40223 [2.8443109e+02 1.4424365e+03 5.1355699e-05 ... 1.6564375e+03 2.5236685e+02\n",
      " 6.6699835e+02]\n",
      "distance 38638 [ 269.36652 1104.5293   109.73776 ...  897.9841   224.54205  454.68967]\n",
      "distance 35380 [252.06548 715.74976 110.22391 ... 883.7538  210.13132 457.91388]\n",
      "distance 12733 [2.5363320e-01 2.8956177e+01 8.6146225e+01 ... 6.3184619e+02 1.8981433e-05\n",
      " 3.8491495e+02]\n",
      "distance 36363 [148.63342  509.062     89.712906 ... 638.4227   127.88806  364.37643 ]\n",
      "distance 32881 [ 96.9447   222.48828   76.1862   ... 605.9237    75.492645 262.39487 ]\n",
      "distance 28247 [117.134155 261.8081   131.95395  ... 530.8833    93.21533  261.391   ]\n",
      "distance 10263 [162.14825  389.65442   75.880875 ... 481.6027   130.57608  283.91113 ]\n",
      "distance 18823 [147.59036 322.7484   70.39909 ... 478.32904 126.10225 307.02917]\n",
      "distance 12425 [ 68.280365 135.99164  113.59997  ... 355.83792   45.344086 243.07684 ]\n",
      "distance 20179 [ 20.348572  37.235657  55.83426  ... 536.5895    24.088287 284.17474 ]\n",
      "distance 5252 [112.39728 211.87311  75.43006 ... 324.793    84.73311 204.94283]\n",
      "distance 32602 [ 83.67232  136.53168   82.024376 ... 286.76068   66.625015 153.59361 ]\n",
      "distance 34253 [127.57151  278.09055   45.427353 ... 349.2977   110.987076 203.26254 ]\n",
      "distance 4328 [3.3078954e-02 8.1972361e+00 4.1596031e+01 ... 2.0336575e+02 6.6377081e-02\n",
      " 1.6058044e+02]\n",
      "distance 19533 [ 78.216736 149.18564   38.00322  ... 192.44922   65.97948  158.5454  ]\n",
      "distance 28987 [ 83.29228 145.74771  57.29177 ... 161.85204  78.63425 131.60712]\n",
      "distance 2171 [20.249298 26.129074 10.871918 ... 58.59675  16.251266 52.370213]\n",
      "distance 41930 [26.561295 35.240555 10.15128  ... 54.7949   26.847763 44.184525]\n",
      "distance 34906 [30.986328 39.066383 25.64207  ... 60.22973  29.59386  43.16913 ]\n",
      "distance 3583 [23.14235  27.37362  23.623913 ... 21.446693 20.109436 23.414055]\n",
      "Obtained 37 clusters from initial clustering\n",
      "Initial clustering took: 2.554263114929199 seconds\n",
      "distance calculation time: 4.262798070907593 seconds\n",
      "count_numbers_of_sharedcontigs took  0.7626206874847412 seconds\n",
      "find_connected_components took  0.00039887428283691406 seconds\n",
      "number of connected components 22\n",
      "count_by_connecting_centroids took  5.034546136856079 seconds\n",
      "distance_calculation: 5.03471827507019\n",
      "overall time taken for new clustering is:  5.0384368896484375\n",
      "[ 37.5  60.   67.5 ... 158.  265.  216. ] 874\n",
      "0 [2212, 874] 874\n",
      "0 [2212, 874] 874\n",
      "0 1 [5286506.945480904, 5316525.225613808]\n",
      "[ 98.5 212.  119.  ...  79.5  75.   87. ] 1138\n",
      "2 [78, 1136] 1138\n",
      "2 [78, 1136] 1138\n",
      "2 0 [2416326.159690858, 2414292.386825543]\n",
      "[145.  146.5 128.5 ... 127.  112.5 145.5] 1583\n",
      "4 [859, 2126] 1583\n",
      "4 [859, 2126] 1583\n",
      "4 0 [3238578.4103596546, 3232883.095063657]\n",
      "[122.5  219.   141.   ... 190.25  74.    98.  ] 899\n",
      "6 [567, 939] 899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yazhini/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 [567, 939] 899\n",
      "6 0 [1663338.2785912915, 1662726.3378422002]\n",
      "[ 242.5  2955.25 3153.   ...  117.5    90.5   203.  ] 164\n",
      "7 [259, 3392] 164\n",
      "[ 242.5  2955.25 3153.   ...  117.5    90.5   203.  ] 164\n",
      "7 [259, 3392, 164] 164\n",
      "7 1 [6321806.277651154, 6360817.001691559, 6352230.854011486]\n",
      "[126.5  76.5  98.  ... 135.   86.  232. ] 2832\n",
      "16 [487, 556] 2832\n",
      "16 [487, 556] 2832\n",
      "16 0 [602947.5195073833, 596051.5745669708]\n",
      "[ 23.         18.5        16.         20.         28.5        19.5\n",
      "  19.         24.5        22.5        35.5        28.         17.5\n",
      "  20.         28.         13.5        24.5        98.         31.\n",
      "  20.5        21.5       157.5        18.         20.        159.\n",
      "  15.5        17.         24.5        13.         40.5        21.\n",
      "  30.5        19.         23.         27.5        23.         50.\n",
      "  19.         23.5        16.5        20.5        20.         38.\n",
      "  20.5        25.5        39.5        66.88892    19.         23.5\n",
      "  21.         27.25       22.         42.         26.5        26.\n",
      "  23.         19.5        17.5        22.         21.5        18.\n",
      "  24.5        65.287728   83.66663    21.25       87.980129   68.5\n",
      "  27.         16.5        57.416694   16.5       102.350493   24.5\n",
      "  23.         23.         32.916674   26.5       111.385572   15.\n",
      "  26.5        16.5        33.5        41.9080614  16.5        33.5\n",
      "  29.5        18.         28.5        21.         28.         32.5\n",
      "  18.         29.5        34.         22.         22.5        24.875004\n",
      "  22.         26.5        20.5        43.5252019  73.7083     30.5\n",
      "  27.5        33.5        21.5        20.5        21.         20.75\n",
      "  22.5        22.5        20.5        34.5        21.5        19.\n",
      "  20.         91.58337    33.         83.1355142  25.5        27.\n",
      "  22.5        25.5        48.         27.5        24.5        23.9031757\n",
      "  18.         29.5        16.5        83.73086    20.         17.\n",
      "  23.         14.5        18.         32.5        17.5        16.\n",
      "  29.         24.5        30.5        24.5        19.5        27.5\n",
      "  18.5        26.5        22.5        20.5        32.         28.5\n",
      "  33.         21.5        24.         52.9442677  27.         21.5\n",
      "  16.         23.5        24.         17.5        86.10837    24.5\n",
      "  29.916678   20.5        26.5        26.         20.         19.\n",
      "  18.5        25.5        19.         54.765926   25.         29.5\n",
      "  25.         18.5        28.0968224  27.         18.5        18.5\n",
      "  22.         18.5        30.         17.         18.         21.\n",
      "  23.1750033  25.5        19.5        16.5        22.         23.\n",
      "  26.5        19.58334    34.58334    33.5        20.         22.5\n",
      "  22.5        19.5        23.5        19.         26.5        16.\n",
      "  22.         18.         35.5        19.5        25.5        19.\n",
      "  19.5        32.         17.5        44.5        20.5982765  23.5\n",
      "  21.5        41.5        35.         37.         18.         22.\n",
      "  19.         36.         28.5        34.         12.         57.684557\n",
      "  61.367041   25.         31.5        17.5        58.25       16.5\n",
      "  73.105089   29.5        16.5        21.5        19.5        22.\n",
      "  18.5        24.         12.5        24.5        26.5        18.5\n",
      "  20.         15.5        19.         52.5        33.25       29.5\n",
      "  27.5        19.         20.5        22.         18.5        17.5\n",
      "  33.5        36.         24.         32.         27.         29.\n",
      "  23.666664   18.         22.         24.         30.5        22.\n",
      "  44.         23.5        26.5        45.8296154  26.5        17.\n",
      "  42.         12.5        28.         15.         30.5        50.5\n",
      "  56.00007    21.         27.5        17.5        60.191707   12.5\n",
      "  30.         40.416697   74.913409   20.         29.5        26.\n",
      "  19.         23.         18.         23.         36.5        24.5\n",
      "  17.         19.         29.350033   21.         19.5        21.\n",
      "  20.         23.         17.         20.5        13.         18.5\n",
      "  19.5        27.         18.5        19.         28.5        22.\n",
      "  69.0284153  19.         21.5        24.5        15.         62.5\n",
      "  74.958297   18.         21.         20.         22.5        23.\n",
      "  17.         17.5        20.5        17.         39.75       17.5\n",
      "  30.5        29.         21.         40.         20.5        27.5\n",
      "  24.         20.         16.         28.         23.5        16.\n",
      "  22.5        46.166708   31.5        28.5        27.         21.5\n",
      "  71.9583     30.5        18.33334    15.         27.5        23.\n",
      "  28.         18.5        43.9960652  33.5        12.5        22.\n",
      "  18.5      ] 23\n",
      "19 [42, 235] 23\n",
      "19 [42, 235] 23\n",
      "19 0 [3531.062882852014, -18574.68944925852]\n",
      "[ 58.    36.    43.    30.5   42.5   40.    26.5   46.5   47.    50.\n",
      "  31.5   42.    40.5   29.5   51.5   34.5   43.    36.    30.5   45.\n",
      "  52.5   38.    55.    34.5   32.    47.5   44.    30.5   50.    37.\n",
      "  45.5   47.    33.    33.5   49.5   35.5   33.    32.5   59.5   28.5\n",
      "  42.5   56.    32.    33.5   40.    55.    39.    33.    20.    48.\n",
      "  43.    40.    48.    75.    45.    38.    34.5   35.5   28.5   40.5\n",
      "  29.    33.5   44.5   30.    36.5   22.    51.    49.5   37.    78.5\n",
      "  55.    38.    50.5   40.    46.5   38.    36.    32.25  43.    35.\n",
      "  40.    42.    36.    60.5   41.5   30.    37.5   31.5   33.5   28.5\n",
      "  25.5   41.5   35.    45.    35.5   32.5   49.   102.    54.    43.5\n",
      "  42.    48.    44.5   42.5   36.    34.5   46.5   41.5   37.5   43.\n",
      "  58.    49.5   39.    33.5   33.    42.5   40.5   46.    33.5  102.75\n",
      "  43.    41.5   44.    40.5   50.5   24.5   41.5   49.5   49.    35.5\n",
      "  32.5   33.5   24.    33.    34.5   37.    39.    29.    46.    52.5\n",
      "  35.    53.5   42.    38.5   38.5   40.    36.5   41.    40.    54.\n",
      " 145.5   38.    52.5   38.5   37.    29.    57.    31.    42.    44.5\n",
      "  35.  ] 150\n",
      "20 [48, 95] 150\n",
      "[ 58.    36.    43.    30.5   42.5   40.    26.5   46.5   47.    50.\n",
      "  31.5   42.    40.5   29.5   51.5   34.5   43.    36.    30.5   45.\n",
      "  52.5   38.    55.    34.5   32.    47.5   44.    30.5   50.    37.\n",
      "  45.5   47.    33.    33.5   49.5   35.5   33.    32.5   59.5   28.5\n",
      "  42.5   56.    32.    33.5   40.    55.    39.    33.    20.    48.\n",
      "  43.    40.    48.    75.    45.    38.    34.5   35.5   28.5   40.5\n",
      "  29.    33.5   44.5   30.    36.5   22.    51.    49.5   37.    78.5\n",
      "  55.    38.    50.5   40.    46.5   38.    36.    32.25  43.    35.\n",
      "  40.    42.    36.    60.5   41.5   30.    37.5   31.5   33.5   28.5\n",
      "  25.5   41.5   35.    45.    35.5   32.5   49.   102.    54.    43.5\n",
      "  42.    48.    44.5   42.5   36.    34.5   46.5   41.5   37.5   43.\n",
      "  58.    49.5   39.    33.5   33.    42.5   40.5   46.    33.5  102.75\n",
      "  43.    41.5   44.    40.5   50.5   24.5   41.5   49.5   49.    35.5\n",
      "  32.5   33.5   24.    33.    34.5   37.    39.    29.    46.    52.5\n",
      "  35.    53.5   42.    38.5   38.5   40.    36.5   41.    40.    54.\n",
      " 145.5   38.    52.5   38.5   37.    29.    57.    31.    42.    44.5\n",
      "  35.  ] 150\n",
      "20 [48, 95, 48] 150\n",
      "20 0 [3345.0549543097595, -6097.865007152373, -6266.580504207908]\n",
      "[ 30.    33.5   35.    43.5   32.    45.    34.    18.5   23.5   25.5\n",
      "  28.5   80.5   27.5   39.    35.5   31.    23.    26.5   34.    29.\n",
      "  30.5   22.    26.5   24.5   38.5   56.    43.    26.5   28.5   26.5\n",
      "  34.    28.    30.    35.    28.    44.5   23.5   24.5   29.5   33.5\n",
      "  29.    41.5   60.5   35.5   28.5   38.5   28.    31.    38.5   30.\n",
      "  22.5   30.    25.    31.5   23.5   44.    28.    58.    29.5   27.\n",
      "  37.5   32.5   16.    26.5   26.5   28.5   33.    26.5   45.    43.5\n",
      "  20.5   29.5   33.    40.5   32.    26.5   25.5   25.    22.5   46.5\n",
      "  25.5   23.    31.    43.5   43.5   72.25  30.5   46.5   23.    27.5\n",
      "  33.    21.5   22.5   41.    31.5   28.5   31.    29.5   53.5   31.5\n",
      "  43.5   38.    26.5   44.5   31.    34.5   28.    61.5   23.5   22.\n",
      "  32.    29.    22.    29.5   35.5   25.5   39.    21.    24.    34.5\n",
      "  34.    24.    31.5   34.    28.5   23.    32.5   29.    28.5   27.5\n",
      "  44.5   34.5   39.    30.5   26.5   24.5   82.    33.5   28.5   21.\n",
      "  55.5   30.    44.5   40.5   26.5   30.5   32.5   27.5   29.5   36.\n",
      "  37.    31.    25.5   36.5   29.    77.75  20.    30.    28.    32.5\n",
      "  27.    18.   104.5   22.5   23.5   22.5   39.    57.    34.    21.5\n",
      "  30.5   32.5   23.5   24.    33.5   29.5   41.    28.5   44.5   41.5\n",
      "  19.5   20.5   26.    22.5   29.    28.5   42.5   35.5   34.5   38.\n",
      "  25.    29.    31.    30.5   24.    28.    23.    33.    34.    34.5\n",
      "  49.5   38.    33.5   27.    36.    32.5   24.5   84.5   46.5   25.5\n",
      "  24.    26.5   20.5   29.    31.5   28.5   34.    26.    26.    27.5\n",
      "  40.5   27.5   47.    43.5   28.    28.    52.5   24.5   40.    26.5\n",
      "  32.5   27.5   28.    22.5   20.    37.5   27.    37.5   24.5   35.5\n",
      "  27.    39.    42.    33.    28.    20.5   33.5   26.5   27.    34.\n",
      "  30.5   19.5   37.    41.5   31.5   29.5   27.    19.5   23.5   32.\n",
      "  27.5   44.    40.    31.    32.    26.5   44.5   25.5   33.5   36.5\n",
      "  56.    28.5   30.5   34.    50.    17.5   31.5   32.5   15.5   27.\n",
      "  31.5   34.5   34.5   21.    27.5   29.5   25.5   30.5   31.5   28.\n",
      "  37.    41.5   27.    29.5   26.5   28.    28.  ] 162\n",
      "21 [292, 5] 162\n",
      "21 [292, 5] 162\n",
      "21 0 [556.8099222827568, -2849.1650819208953]\n",
      "(20, 24)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from optimize_parameters import optimize_alpha\n",
    "from distance_calculations_source import distance\n",
    "from new_clustering_algorithm import cluster_by_connecting_centroids\n",
    "\n",
    "def np_relu(x):\n",
    "    \n",
    "    return np.maximum(0,x)\n",
    "\n",
    "\n",
    "def initialize_Z(W, dat):\n",
    "    \n",
    "    W_t = np.transpose(W)\n",
    "    lmda = 0.1\n",
    "    inverse_term = np.linalg.inv(np.eye(W.shape[0]) + (lmda ** -1) * np.matmul(W,W_t))\n",
    "    woodbury = (lmda ** -1) * np.eye(W.shape[1]) - np.matmul((lmda ** -2) * W_t , np.matmul(inverse_term, W))\n",
    "    Z = np_relu(np.matmul(woodbury, np.matmul(W_t,dat)))\n",
    "    \n",
    "    return Z\n",
    "\n",
    "\n",
    "def maximize_function(w, z, x):\n",
    "    \n",
    "    mean = np.matmul(w, z)\n",
    "    mean = 1e-10 + np_relu(mean)\n",
    "    negative_log_likelihood = np.sum(- mean + np.multiply(x, np.log(mean)))\n",
    "\n",
    "    return negative_log_likelihood\n",
    "\n",
    "\n",
    "def calc_aic(w, z, x):\n",
    "\n",
    "    mean = np.matmul(w, z)\n",
    "    mean = 1e-10 + np_relu(mean)\n",
    "    log_likelihood = np.sum(- mean + np.multiply(x, np.log(mean)))\n",
    "    # print('differences', np.count_nonzero(np_relu(w) > 1e-05) - np.count_nonzero(np_relu(z) > 1e-05))\n",
    "    AIC = log_likelihood - np.count_nonzero(np_relu(w) > 1e-05) - np.count_nonzero(np_relu(z) > 1e-05)\n",
    "    \n",
    "    return AIC\n",
    "\n",
    "\n",
    "\"\"\" Multiplicative Updates \"\"\"\n",
    "\n",
    "def multiplicative_updates(W, Z, X, n, method):\n",
    "    \n",
    "    lw = 0.0\n",
    "    lz = 1e-01\n",
    "    beta = 0.5\n",
    "    convergence_criteria = 0.0001\n",
    "    epsilon_reg = 1e-05\n",
    "    loss_values = []\n",
    "    \n",
    "    global AIC\n",
    "    \n",
    "    if method == 0:\n",
    "        \n",
    "        for i in range(n):\n",
    "\n",
    "            mean = np.matmul(W, Z)\n",
    "            mean = 1e-10 + np_relu(mean)\n",
    "            X_by_mean = X / mean\n",
    "\n",
    "            W = np.multiply(W, np_relu(np.matmul(X_by_mean, np.transpose(Z))))\n",
    "            W = W / np.sum(W, axis = 0)\n",
    "            Z = np.multiply(Z, np_relu(np.matmul(np.transpose(W), X_by_mean)))\n",
    "\n",
    "            loss_values.append(maximize_function(W, Z, X))\n",
    "            \n",
    "            if len(loss_values) >= 10 :\n",
    "                \n",
    "                if ((loss_values[i] - loss_values[i-10]) / loss_values[i]) < convergence_criteria:\n",
    "                    AIC = calc_aic(W, Z, X)\n",
    "                    # print(\"Function is converged\")\n",
    "                    break\n",
    "        return  W, Z, loss_values, AIC\n",
    "    \n",
    "    \n",
    "    if method == 1:\n",
    "        \n",
    "        for i in range(n):\n",
    "\n",
    "            mean = np.matmul(W, Z)\n",
    "            mean = 1e-10 + np_relu(mean)\n",
    "            X_by_mean = X / mean\n",
    "\n",
    "            Z_reg =  (lz * beta) / np.power(np.abs(Z+epsilon_reg), 1-beta)\n",
    "            Z = np.multiply(Z, np_relu(np.matmul(np.transpose(W), X_by_mean) - Z_reg))\n",
    "            \n",
    "            loss_values.append(maximize_function(W, Z, X))\n",
    "\n",
    "            if len(loss_values) >= 10 :\n",
    "                if ((loss_values[i] - loss_values[i-10]) / loss_values[i]) < convergence_criteria:\n",
    "                    AIC = calc_aic(W, Z, X)\n",
    "                    # print(\"Function is converged\")\n",
    "                    break\n",
    "                \n",
    "        return  Z, loss_values, AIC\n",
    "    \n",
    "    \n",
    "    if method == 2:\n",
    "        \n",
    "        for i in range(n):\n",
    "\n",
    "            mean = np.matmul(W, Z)\n",
    "            mean = 1e-10 + np_relu(mean)\n",
    "            X_by_mean = X / mean\n",
    "\n",
    "            W_reg =  (lw * beta) / np.power(np.abs(W+epsilon_reg), 1-beta)\n",
    "            Z_reg =  (lz * beta) / np.power(np.abs(Z+epsilon_reg), 1-beta)\n",
    "\n",
    "            W = np.multiply(W, np_relu(np.matmul(X_by_mean, np.transpose(Z)) - W_reg))\n",
    "            W = W / np.sum(W, axis = 0) \n",
    "            Z = np.multiply(Z, np_relu(np.matmul(np.transpose(W), X_by_mean) - Z_reg))\n",
    "\n",
    "            loss_values.append(maximize_function(W, Z, X))\n",
    "\n",
    "            # if len(loss_values) >= 10 :\n",
    "            #     if ((loss_values[i] - loss_values[i-10]) / loss_values[i]) < convergence_criteria:\n",
    "            #         AIC = calc_aic(W, Z, X)\n",
    "            #         # print(\"Function is converged\")\n",
    "            #         break\n",
    "                \n",
    "        return  W, Z, loss_values, AIC\n",
    "\n",
    "    \n",
    "\"\"\" End multiplicative updates \"\"\"\n",
    "                               \n",
    "                                \n",
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    s = time.time()\n",
    "    print(\"clustering initiated\")\n",
    "    tmp_dir = \"/big/work/metadevol/benchmark_dataset1/\"\n",
    "    # tmp_dir = \"/big/work/metadevol/scripts/bamtools_api/build/\"\n",
    "    dat = pd.read_pickle(tmp_dir + 'X_pickle')\n",
    "    contig_names = dat.columns\n",
    "    d0 = 1\n",
    "    min_shared_contigs = 5\n",
    "    s_start = time.time()\n",
    "    clusters, numclust_incomponents, an, alpha, N = cluster_by_connecting_centroids(dat, d0, min_shared_contigs)\n",
    "    print(\"distance_calculation:\", time.time() - s_start)\n",
    "    print(\"overall time taken for new clustering is: \", time.time()-s)\n",
    "    \n",
    "    label = pd.read_csv(tmp_dir + 'contigs_ids_distindex', sep =' ', header = None)\n",
    "    # label = pd.read_csv(tmp_dir + 'contigs_refid_genomeid_withcrossmappeddata', sep =' ', header = None)\n",
    "    lc = np.array(label[3])\n",
    "    \n",
    "    dat = dat.to_numpy()\n",
    "\n",
    "    dat = read_counts\n",
    "   \n",
    "    num_iterations = 100\n",
    "    \n",
    "    W_full = []\n",
    "    Z_zbc_lcov = []\n",
    "    epsilon = 1e-10\n",
    "\n",
    "\n",
    "    for k in np.arange(len(numclust_incomponents)):\n",
    "\n",
    "        if numclust_incomponents[k] > 1 :\n",
    "            dat_s = dat[:, clusters[k]]\n",
    "            lc_s = lc[clusters[k]]\n",
    "            Rc_s = dat_s.sum(axis = 0)\n",
    "            AIC_score = []\n",
    "            \n",
    "            optimized = {}\n",
    "            \n",
    "            LL_values = {}\n",
    "            \n",
    "            for _ in range(3):\n",
    "                \n",
    "                trial_bval = _\n",
    "                k_contigs = []\n",
    "\n",
    "                if trial_bval == 0:\n",
    "                    k_contigs = dat_s.sum(axis=1) + epsilon\n",
    "                    k_contigs = k_contigs.reshape(N,1)\n",
    "\n",
    "                else:\n",
    "                    if trial_bval + 1 <= numclust_incomponents[k]: \n",
    "\n",
    "                        ind = []\n",
    "\n",
    "                        for i in range(trial_bval+1):\n",
    "\n",
    "                            if i == 0:\n",
    "\n",
    "                                c0_ind = np.argmax(dat_s.sum(axis=0))\n",
    "                                print(dat_s.sum(axis=0), c0_ind)\n",
    "                                c0 = dat_s[:, [c0_ind]]\n",
    "                                dist = distance(c0, dat_s, Rc_s[c0_ind], Rc_s, N, an, alpha)\n",
    "                                c_ind = np.argmax(dist)\n",
    "                                c = dat_s[:, [c_ind]]\n",
    "                                k_contigs = c\n",
    "                                ind.append(c_ind)\n",
    "\n",
    "                            else:\n",
    "\n",
    "                                dist_sum = []\n",
    "\n",
    "                                for f in range(np.shape(k_contigs)[1]):\n",
    "                                    dist_sum.append(distance(k_contigs[:,[f]],dat_s, Rc_s[ind[f]], Rc_s, N, an, alpha))\n",
    "                                # print('distance', np.shape(np.array(dist_sum)),  np.max(np.array(dist_sum)), np.array(dist_sum).sum(axis=0))\n",
    "                                f_ind = np.argmax(np.array(dist_sum).sum(axis=0))\n",
    "                                ind.append(f_ind)\n",
    "                                k_contigs = np.hstack((k_contigs, dat_s[:, [f_ind]])) \n",
    "                    print(k, ind, c0_ind)\n",
    "                W = np.array(k_contigs) \n",
    "                \n",
    "                W_norm = W / W.sum(axis = 0)\n",
    "            \n",
    "                if not np.shape(W)[0] == 0:\n",
    "                    \n",
    "                    Z = initialize_Z(W_norm, dat_s)\n",
    "\n",
    "                    W_opt, Z_opt, LL, AIC = multiplicative_updates(W_norm, Z, dat_s, num_iterations, 0)\n",
    "                    optimized[\"W\"+str(trial_bval)] = W_opt\n",
    "                    optimized[\"Z\"+str(trial_bval)] = Z_opt\n",
    "                    AIC_score.append(AIC)\n",
    "                    LL_values[str(trial_bval)] = LL\n",
    "\n",
    "            # obtain best k using maximum AIC value    \n",
    "            bval = np.argmax(AIC_score)\n",
    "            print(k, bval, AIC_score)\n",
    "            W_full.append(optimized[\"W\"+str(bval)])\n",
    "            # z_bc = optimized[\"Z\"+str(bval)]\n",
    "            # weights = (optimized[\"Z\"+str(bval)] ** 5) / (Rc_s ** 4)\n",
    "            # weights_summedoverC = np.sum(weights, axis=1, keepdims = True)\n",
    "            # small_cov_b = np.sum((weights * (z_bc / lc_s) / weights_summedoverC), axis=1, keepdims=True)\n",
    "            # z_bc_corrected = z_bc/(lc_s * small_cov_b)\n",
    "            # Z_zbc_lcov.append(z_bc_corrected)\n",
    "            # zbcsum_value = np.sum(z_bc_corrected, axis=0)\n",
    "            # print(k, np.min(zbcsum_value), np.max(zbcsum_value))\n",
    "            # if k == 21:\n",
    "            #     print(z_bc_corrected[:,np.nonzero(clusters[k] == 41399)])\n",
    "\n",
    "        else:\n",
    "\n",
    "            dat_s = dat[:, clusters[k]].sum(axis=1) + epsilon\n",
    "            dat_s = dat_s.reshape(N,1) \n",
    "            dat_s = dat_s / dat_s.sum() # not resulting in 1.0 (eg., 0.9999999999999998, 1.0000000000000002)\n",
    "            W_full.append(dat_s)\n",
    "            # z_bc = initialize_Z(dat_s, dat_s)\n",
    "            # weights = (z_bc ** 5) / (Rc_s ** 4)\n",
    "            # weights_summedoverC = np.sum(weights, axis=1, keepdims = True)\n",
    "            # small_cov_b = np.sum((weights * (z_bc / lc_s) / weights_summedoverC), axis=1, keepdims=True)\n",
    "            # Z_zbc_lcov.append(z_bc/(lc_s * small_cov_b))\n",
    "\n",
    "    W_full = np.concatenate(W_full, axis = 1)\n",
    "    # Z_zbc_lcov = np.concatenate(Z_zbc_lcov, axis = 0)\n",
    "    print(np.shape(W_full))\n",
    "\n",
    "    Z = initialize_Z(W_full, dat)\n",
    "    \n",
    "    # LL.append(maximize_function(W_full, Z, dat))\n",
    "\n",
    "    Z_full, LL, AIC_score = multiplicative_updates(W_full, Z, dat, num_iterations, 1)\n",
    "    # LL.append(LL_values)\n",
    "    \n",
    "    # plt.plot(LL)\n",
    "    # W_fullopt, Z_fullopt, LL, AIC_final = multiplicative_updates(W_full, Z_full, dat, num_iterations, 2)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # \"\"\" Assignment \"\"\"\n",
    "    # Z_assign = Z_full\n",
    "    # Rc_c  = np.sum(Z_assign, axis=0)\n",
    "    # pb_c  = Z_assign / Rc_c\n",
    "    # cov_b = np.sum(Z_assign, axis=1) / np.sum((np.array(lc) * Z_assign) / Rc_c, axis=1)\n",
    "    # pb_min = 0.8 * (cov_b.reshape(len(cov_b),1) * np.sum(np.square(pb_c), axis=0) \\\n",
    "    #                 / np.sum(cov_b.reshape(len(cov_b),1) * pb_c, axis=0))\n",
    "    # pb_min[pb_min > 0.5] = 0.5\n",
    "    # contig_assign0 = np.argmax(pb_c/pb_min, axis=0)\n",
    "    \n",
    "    # print(len(set(contig_assign0)), \"number of bins\")\n",
    "    # print(len(set(np.argmax(Z_assign, axis=0))), \"just max\")\n",
    "\n",
    "\n",
    "    # \"\"\" New assignment - more than one bins for contigs is possible\"\"\"\n",
    "    Z_assign = Z_full\n",
    "    Rc_c  = np.sum(Z_assign, axis=0)\n",
    "    pb_c  = np.power(Z_assign/Rc_c,4)\n",
    "    Z_l = Z_assign / np.array(lc)\n",
    "\n",
    "    cov_b = (np.multiply(pb_c,Z_l).sum(axis=1)) / pb_c.sum(axis=1)\n",
    "\n",
    "    pi_bc1 = Z_assign / np.row_stack(cov_b)\n",
    "    pi_bc2 = pi_bc1.sum(axis=0)\n",
    "\n",
    "    pi_bc = pi_bc1 / pi_bc2\n",
    "\n",
    "    np.argwhere(pi_bc>0.2)\n",
    "    # np.savetxt(tmp_dir + \"indices_pibc_bins\",np.argwhere(pi_bc>0.2), fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd53b733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  C_CONTIGUOUS : False\n",
       "  F_CONTIGUOUS : True\n",
       "  OWNDATA : False\n",
       "  WRITEABLE : True\n",
       "  ALIGNED : True\n",
       "  WRITEBACKIFCOPY : False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.flags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e980d349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fractional_counts = pd.read_csv(tmp_dir + 'total_count',header=None,sep=' ')\n",
    "# read_counts = fractional_counts.pivot_table(index = 1, columns = 0, values = 2)\n",
    "\n",
    "read_counts = read_counts.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055f7a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.03216342e-01, 5.04416327e-01, 4.31220801e-01],\n",
       "       [4.84399018e-01, 4.34504997e-01, 4.01707510e-01],\n",
       "       [0.00000000e+00, 9.68180751e-03, 5.81214131e-02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 4.83085844e-02, 0.00000000e+00],\n",
       "       [0.00000000e+00, 3.03211423e-03, 0.00000000e+00],\n",
       "       [7.87679411e-04, 0.00000000e+00, 1.40293616e-02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 6.43666011e-03],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.75709611e-04, 2.84687512e-02, 1.84738864e-03],\n",
       "       [1.48484269e-03, 0.00000000e+00, 2.04989438e-02],\n",
       "       [3.97936401e-05, 0.00000000e+00, 3.23210224e-05],\n",
       "       [5.26605573e-04, 6.91225876e-04, 1.44815540e-02],\n",
       "       [8.69827240e-04, 4.36774430e-03, 0.00000000e+00],\n",
       "       [2.60858251e-02, 3.92420981e-05, 1.98966670e-02],\n",
       "       [2.69741787e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.55017693e-02, 5.92802643e-03, 5.40175145e-04],\n",
       "       [4.96920596e-03, 1.28142867e-04, 0.00000000e+00],\n",
       "       [0.00000000e+00, 1.29204462e-03, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "       [8.44281381e-03, 3.01676736e-02, 4.56816454e-02],\n",
       "       [0.00000000e+00, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "# rand_ind = [random.sample(list(label[label[4]==\"17_7\"][0]),2)]\n",
    "# (Z_l/np.row_stack(cov_b))[:,rand_ind]\n",
    "(Z_l/np.row_stack(cov_b))[:,[35892, 35964,38109]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6c7962",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 number of bins\n",
      "6 just max\n"
     ]
    }
   ],
   "source": [
    "Z_assign = Z_full\n",
    "Rc_c  = np.sum(Z_assign, axis=0)\n",
    "pb_c  = np.power(Z_assign, 5) / np.power(Rc_c,4) \n",
    "cov_b = np.sum(Z_assign, axis=1) / np.sum((np.array(lc) * Z_assign) / Rc_c, axis=1)\n",
    "pb_min = 0.8 * (cov_b.reshape(len(cov_b),1) * np.sum(np.square(pb_c), axis=0) \\\n",
    "                / np.sum(cov_b.reshape(len(cov_b),1) * pb_c, axis=0))\n",
    "pb_min[pb_min > 0.5] = 0.5\n",
    "contig_assign0 = np.argmax(pb_c, axis=0)\n",
    "\n",
    "print(len(set(contig_assign0)), \"number of bins\")\n",
    "print(len(set(np.argmax(Z_assign, axis=0))), \"just max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3b8f5a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 number of bins\n",
      "24 just max\n"
     ]
    }
   ],
   "source": [
    "Z_assign = Z_full\n",
    "Rc_c  = np.sum(Z_assign, axis=0)\n",
    "pb_c  = Z_assign / Rc_c\n",
    "cov_b = np.sum(Z_assign, axis=1) / np.sum((np.array(lc) * Z_assign) / Rc_c, axis=1)\n",
    "pb_min = 0.8 * (cov_b.reshape(len(cov_b),1) * np.sum(np.square(pb_c), axis=0) \\\n",
    "                / np.sum(cov_b.reshape(len(cov_b),1) * pb_c, axis=0))\n",
    "pb_min[pb_min > 0.5] = 0.5\n",
    "contig_assign0 = np.argmax(pb_c/pb_min, axis=0)\n",
    "contig_pbc_value = np.max(pb_c,axis=0)\n",
    "\n",
    "print(len(set(contig_assign0)), \"number of bins\")\n",
    "print(len(set(np.argmax(Z_assign, axis=0))), \"just max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afb5910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, fi in zip(clusters, range(len(clusters))):\n",
    "    f = f.flatten()\n",
    "    for q in f:\n",
    "        with open(\"/big/work/metadevol/benchmark_dataset1/\" + \"connected_components_check1\", 'a') as file:\n",
    "#         # with open(\"/big/work/metadevol/scripts/bamtools_api/build/\" + \"connected_components_new\", 'a') as file:\n",
    "#             for r in q:\n",
    "#                 print(r, fi)\n",
    "            file.write(str(q) + \" \" + str(fi) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98b972bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_assign = Z_full\n",
    "Rc_c  = np.sum(Z_assign, axis=0)\n",
    "pb_c  = np.power(Z_assign/Rc_c,4) \n",
    "Z_l = Z_assign / np.array(lc)\n",
    "\n",
    "cov_b = (np.multiply(pb_c,Z_l).sum(axis=1)) / pb_c.sum(axis=1)\n",
    "\n",
    "pi_bc1 = Z_assign / np.row_stack(cov_b)\n",
    "pi_bc2 = pi_bc1.sum(axis=0)\n",
    "\n",
    "pi_bc = pi_bc1 / pi_bc2\n",
    "\n",
    "# np.savetxt(tmp_dir + \"indices_pibc_bins\",np.argwhere(pi_bc>0.2), fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "169a1bc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0042649 , 0.0041205 , 0.00138908, ..., 0.75907716, 0.78543794,\n",
       "        0.7880203 ],\n",
       "       [0.36774979, 0.41072222, 0.40672343, ..., 0.0940474 , 0.07337183,\n",
       "        0.07211987],\n",
       "       [0.00122316, 0.02071317, 0.02274581, ..., 0.00542335, 0.01106666,\n",
       "        0.01153728],\n",
       "       ...,\n",
       "       [0.59200983, 0.39401705, 0.39701159, ..., 0.01940014, 0.01781758,\n",
       "        0.01820378],\n",
       "       [0.01271876, 0.07127645, 0.06574972, ..., 0.01615155, 0.0229985 ,\n",
       "        0.02359419],\n",
       "       [0.        , 0.01031581, 0.01178539, ..., 0.00474204, 0.00896495,\n",
       "        0.00933211]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379e7635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(np.count_nonzero(pi_bc>0.3, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "003fcc11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1755"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(clusters[8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd40326a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_assign = Z_full\n",
    "Rc_c  = np.sum(Z_assign, axis=0)\n",
    "pb_c  = Z_assign / Rc_c\n",
    "cov_b = np.sum(Z_assign, axis=1) / np.sum((np.array(lc) * Z_assign) / Rc_c, axis=1)\n",
    "pb_min = 0.8 * (cov_b.reshape(len(cov_b),1) * np.sum(np.square(pb_c), axis=0) \\\n",
    "                / np.sum(cov_b.reshape(len(cov_b),1) * pb_c, axis=0))\n",
    "pb_min[pb_min > 0.5] = 0.5\n",
    "contig_assign0 = np.argmax(pb_c/pb_min, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15793a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.71654389e+01, 6.45370003e+01, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 8.43156582e-02, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 1.12237097e-01, 1.58307353e-01,\n",
       "       3.99826554e-03, 5.72532305e-02, 8.50388144e-02, 1.33830140e+00,\n",
       "       2.01656412e-02, 8.51930949e-01, 3.32148564e-01, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 7.21986363e-01, 0.00000000e+00])"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_assign[:,35892]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0593299e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.05974787, 0.08411699, 0.07775508, 0.04731036, 0.09387603,\n",
       "       0.0718943 , 0.06773081, 0.04697633, 0.08803515, 0.08318467,\n",
       "       0.0809913 , 0.06747896, 0.06373598, 0.06879131, 0.06197775,\n",
       "       0.03263422, 0.04760339, 0.03518985, 0.04260547, 0.05545636,\n",
       "       0.03805685, 0.03169541, 0.05495962, 0.03726061])"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6aebb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.30963903e-03, 0.00000000e+00, 4.19058874e-01, 0.00000000e+00,\n",
       "       0.00000000e+00, 4.02193215e-03, 0.00000000e+00, 1.10725641e-01,\n",
       "       0.00000000e+00, 3.32543717e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       1.42169599e-03, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "       6.09904625e-05, 5.70199573e+00, 0.00000000e+00, 5.89651496e+00])"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_assign[:,39905]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eaba868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02625989, 0.06664234, 0.07372199, 0.04344115, 0.08419587,\n",
       "       0.06165101, 0.06357543, 0.04233294, 0.05510622, 0.03009292,\n",
       "       0.0731706 , 0.06334812, 0.05837392, 0.0644841 , 0.0554855 ,\n",
       "       0.02913992, 0.04295817, 0.02792942, 0.03763562, 0.03511042,\n",
       "       0.02874942, 0.01365748, 0.01935618, 0.01382941])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3cce50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(np.count_nonzero(pi_bc>=0.1, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67414c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  7.7705915  122.50006542]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([2.36987265e+03, 1.58892151e+53])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "import simdefy as sm\n",
    "\n",
    "sm.init()\n",
    "\n",
    "log_gamma = sm.log_gamma_avx2\n",
    "\n",
    "# def factorial(x):\n",
    "#     return log_gamma(x + 1)\n",
    "\n",
    "def train_alpha(param):\n",
    "    a, b = param\n",
    "    first_term = log_gamma(Rc+a)\n",
    "    second_term = log_gamma(a)\n",
    "    third_term = a * np.log(b/lc)\n",
    "    fourth_term = (Rc + a) * np.log(1 + (b/lc))\n",
    "    maximize_term = (first_term - second_term + third_term - fourth_term).sum()\n",
    "    return -maximize_term\n",
    "\n",
    "def optimize_negbin_params(*argv):\n",
    "    Rc = argv[0]\n",
    "    lc = np.array(argv[1])\n",
    "    a = 0.8\n",
    "    Rc_lc = (Rc / lc).sum() / len(lc)\n",
    "    b = a * 1 / Rc_lc\n",
    "    # fun = lambda a, b: train_alpha(a, b, Rc, lc)\n",
    "    optimize_alpha = minimize(train_alpha, [a, b], method = 'nelder-mead')\n",
    "    print(optimize_alpha.x)\n",
    "    return np.exp(optimize_alpha.x)\n",
    "\n",
    "Rc = dat.sum(axis=0)\n",
    "\n",
    "optimize_negbin_params(Rc, lc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c26bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'K value')"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(AIC_score, marker='o', color=\"g\")\n",
    "plt.xticks(np.arange(0, 3.2, 1))\n",
    "plt.ylabel(\"AIC value\")\n",
    "plt.xlabel(\"K value\")\n",
    "# plt.savefig(\"/big/work/metadevol/benchmark_dataset1/AIC_cc7.png\", format='png', dpi=600, bbox_inches = \"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a484acd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, ' iteration')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# LL = [3196371.6856573387, 3241404.4103596546, 3241404.410359654, 3241404.410359654, 3241404.4103596546, 3241404.4103596546, 3241404.4103596546, 3241404.4103596546, 3241404.4103596546, 3241404.4103596546, 3241404.4103596546]\n",
    "plt.plot(LL, marker='o', color=\"g\")\n",
    "# plt.xticks(np.arange(0, 3.2, 1))\n",
    "plt.ylabel(\"negative loglikelihood\")\n",
    "plt.xlabel(\" iteration\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355f9223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 number of bins\n",
      "24 just max\n"
     ]
    }
   ],
   "source": [
    "Z_assign = Z_full\n",
    "Rc_c  = np.sum(Z_assign, axis=0)\n",
    "pb_c  = Z_assign / Rc_c\n",
    "cov_b = np.sum(Z_assign, axis=1) / np.sum((np.array(lc) * Z_assign) / Rc_c, axis=1)\n",
    "pb_min = 0.8 * (cov_b.reshape(len(cov_b),1) * np.sum(np.square(pb_c), axis=0) \\\n",
    "                / np.sum(cov_b.reshape(len(cov_b),1) * pb_c, axis=0))\n",
    "pb_min[pb_min > 0.5] = 0.5\n",
    "contig_assign0 = np.argmax(pb_c/pb_min, axis=0)\n",
    "contig_assign0 = np.argmax(Z_assign, axis=0)\n",
    "print(len(set(contig_assign0)), \"number of bins\")\n",
    "print(len(set(tf.argmax(Z_assign, axis=0).numpy())), \"just max\")\n",
    "\n",
    "contigs_assigned = []\n",
    "for f in range(np.shape(Z_assign)[1]):\n",
    "    contigs_assigned.append(Z_assign[contig_assign0[f],f])\n",
    "\n",
    "bins0 = np.c_[np.array(contig_names),contig_assign0]\n",
    "\n",
    "np.shape(bins0)\n",
    "\n",
    "np.savetxt(tmp_dir + \"contigbins_onlyZassign\" , bins0, delimiter = \" \", fmt=['%d','%d'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a65866",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02625989, 0.06664234, 0.07372199, 0.04344115, 0.08419587,\n",
       "       0.06165101, 0.06357543, 0.04233294, 0.05510622, 0.03009292,\n",
       "       0.0731706 , 0.06334812, 0.05837392, 0.0644841 , 0.0554855 ,\n",
       "       0.02913992, 0.04295817, 0.02792942, 0.03763562, 0.03511042,\n",
       "       0.02874942, 0.01365748, 0.01935618, 0.01382941])"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_assign[:,38109]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ca37c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 number of bins\n"
     ]
    }
   ],
   "source": [
    "    \n",
    "    # \"\"\" Assignment \"\"\"\n",
    "Rc_c  = np.sum(Z, axis=0)\n",
    "pb_c  = Z / Rc_c\n",
    "cov_b = np.sum(Z, axis=1) / np.sum((np.array(lc) * Z) / Rc_c, axis=1)\n",
    "pb_min = 0.8 * (cov_b.reshape(len(cov_b),1) * np.sum(np.square(pb_c), axis=0) \\\n",
    "                / np.sum(cov_b.reshape(len(cov_b),1) * pb_c, axis=0))\n",
    "pb_min[pb_min > 0.5] = 0.5\n",
    "contig_assign0 = tf.argmax(pb_c/pb_min, axis=0).numpy()\n",
    "\n",
    "print(len(set(contig_assign0)), \"number of bins\")\n",
    "    # print(len(set(tf.argmax(pb_c, axis=0).numpy())), \"just max\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
