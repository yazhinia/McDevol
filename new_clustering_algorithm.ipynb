{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering initiated\n",
      "\n",
      "alpha optimized is: 8.440742299720526 and took 1.7432684898376465 seconds\n",
      "\n",
      "member size 1981 1970 1981\n",
      "member size 1369 1369 1369\n",
      "member size 1170 1157 1170\n",
      "member size 1709 1709 1709\n",
      "member size 2804 2679 2804\n",
      "member size 3797 3797 3797\n",
      "member size 1739 1716 1739\n",
      "member size 8283 5647 8283\n",
      "member size 1755 1755 1755\n",
      "member size 2557 2557 2557\n",
      "member size 2470 2470 2470\n",
      "member size 1649 1167 145\n",
      "member size 1164 1164 1164\n",
      "member size 2433 2433 2433\n",
      "member size 567 455 85\n",
      "member size 1127 1127 1127\n",
      "member size 1668 1668 1668\n",
      "member size 1188 1188 1188\n",
      "member size 3278 3105 3278\n",
      "member size 1340 1246 219\n",
      "member size 1051 1051 1040\n",
      "member size 1197 1197 1197\n",
      "member size 128 127 2\n",
      "member size 1567 1567 1567\n",
      "member size 175 175 2\n",
      "member size 248 247 174\n",
      "member size 116 116 4\n",
      "member size 17 17 4\n",
      "member size 26 26 3\n",
      "member size 366 361 366\n",
      "member size 33 33 1\n",
      "member size 159 151 159\n",
      "member size 294 283 294\n",
      "member size 9 9 1\n",
      "member size 14 14 3\n",
      "member size 6 6 1\n",
      "member size 1 1 1\n",
      "45760 45760 45760\n",
      "Obtained 37 clusters from initial clustering\n",
      "Initial clustering took: 2.261504650115967 seconds\n",
      "count_numbers_of_sharedcontigs took  1.3162288665771484 seconds\n",
      "find_connected_components took  0.00042939186096191406 seconds\n",
      "[2 1 2 1 2 1 2 7 1 1 1 1 1 1 1 1 2 1 1 2 3 2]\n",
      "number of connected components 22\n",
      "count_by_connecting_centroids took  5.3300018310546875 seconds\n",
      "overall time taken for new clustering is:  5.334145784378052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yazhini/.local/lib/python3.8/site-packages/numpy/core/fromnumeric.py:2009: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  result = asarray(a).shape\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from multiprocessing import Pool\n",
    "from optimize_alpha import optimize_alpha\n",
    "from distance_calculations_source import distance\n",
    "# from distance_calculations import distance\n",
    "\n",
    "def compute_distance(dat, c, Rc, N, an, alpha):\n",
    "    # pool = Pool()\n",
    "    dist = distance(dat[:,c], dat, Rc[c], Rc, N, an, alpha, 0)\n",
    "    return dist\n",
    "\n",
    "def cluster_by_centroids(dat, d0, N, C, Rc, Rn):\n",
    "\n",
    "    members = []\n",
    "    members1 = []\n",
    "    cluster_curr = 0\n",
    "    cluster_assigned = np.zeros(C) - 1\n",
    "    cluster_assigned1 = np.zeros(C) - 1\n",
    "\n",
    "    dist_to_assigned = np.zeros(dat.shape[1], dtype=float) + d0\n",
    "\n",
    "    dists = []\n",
    "\n",
    "    s = time.time()\n",
    "    a     = optimize_alpha(dat, Rc, Rn, N)\n",
    "    an    = a * Rn / Rn.sum()\n",
    "    alpha = an.sum()\n",
    "    print(\"alpha optimized is:\",a, \"and took\", time.time() - s, \"seconds\\n\")\n",
    "    s = time.time()\n",
    "    iterate_ind = np.argsort(Rc)[::-1]\n",
    "\n",
    "    for c in iterate_ind:\n",
    "    # for c in np.arange(C):\n",
    "\n",
    "        if cluster_assigned1[c] < 0 :\n",
    "            ss = time.time()\n",
    "            dist = compute_distance(dat, c, Rc, N, an, alpha)\n",
    "            reassign_ind = np.intersect1d(np.nonzero(cluster_assigned < 0)[0], np.nonzero(np.array(dist < d0))[0])\n",
    "            \n",
    "            # print(len(reassign_ind), len(inds))\n",
    "            members.append(reassign_ind)\n",
    "            cluster_assigned[reassign_ind] = cluster_curr\n",
    "\n",
    "            inds = np.nonzero(dist < dist_to_assigned)[0]\n",
    "            dist_to_assigned[inds] = dist[inds]\n",
    "            if len(inds) != 0: \n",
    "                members1.append(inds)\n",
    "                cluster_assigned1[inds] = cluster_curr\n",
    "\n",
    "            dists.append([dist])\n",
    "            cluster_curr += 1\n",
    "\n",
    "\n",
    "            # print(len(members[-1]), len(members1[-1]))\n",
    "    # with open(\"/big/work/metadevol/benchmark_dataset1/initial_clusters_new\", 'a') as file:\n",
    "    #     for f in range(len(members)):\n",
    "    #         for q in members[f]:\n",
    "    #             file.write(str(q) + \" \" + str(f) + \"\\n\")\n",
    "    sum_t = 0\n",
    "    sum_m1 = 0\n",
    "    sum = 0\n",
    "    for k in range(len(members1)):\n",
    "        print(\"member size\", len(members1[k]), len(np.nonzero(cluster_assigned1==k)[0]), len(members[k]))\n",
    "        members1[k] = np.intersect1d(members1[k],np.nonzero(cluster_assigned1==k)[0])\n",
    "        sum_t = sum_t + len(np.nonzero(cluster_assigned1==k)[0])\n",
    "        sum_m1 = sum_m1 + len(members1[k])\n",
    "        sum = sum + len(members[k])\n",
    "    print(sum_t, sum_m1, sum)\n",
    "    print(\"Obtained {} clusters from initial clustering\".format(len(members)))\n",
    "    print(\"Initial clustering took:\", time.time() - s,\"seconds\")\n",
    "\n",
    "    return members, np.array(dists).squeeze()\n",
    "\n",
    "\n",
    "def count_numbers_of_sharedcontigs(dists, d1, min_shared_contigs):\n",
    "    s = time.time()\n",
    "    K, C = np.shape(dists)\n",
    "    shared = np.zeros([K,K])\n",
    "    # shared1 = np.zeros([K,K])\n",
    "    neigh = np.array(dists < d1).astype(int)\n",
    "    neigh_sum = neigh.sum(axis=0)\n",
    "    for c in np.arange(C):\n",
    "        if neigh_sum[c] >= 2:\n",
    "            non_zeroind = neigh[:,c].nonzero()\n",
    "            k_ind = np.array(np.meshgrid(non_zeroind,non_zeroind)).T.reshape(-1,2)\n",
    "            # k_ind = k_ind[k_ind[:,0] != k_ind[:,1]]\n",
    "            for i in k_ind:\n",
    "                shared[i[0],i[1]] += 1\n",
    "    shared = np.array(shared > min_shared_contigs).astype(int)\n",
    "\n",
    "    # for c in np.arange(C):\n",
    "\n",
    "    #     neigh = np.nonzero(np.array(dists)[:,c] < d1)[0]\n",
    "    #     if len(neigh) >= 2:\n",
    "    #         for k in neigh:\n",
    "    #             for l in neigh:\n",
    "    #                 shared[k,l] += 1\n",
    "\n",
    "    # shared = np.array(shared > min_shared_contigs).astype(int)\n",
    "    # print(shared1)\n",
    "\n",
    "    links = []\n",
    "    for k in np.arange(K):\n",
    "        links.append(list(np.nonzero(shared[k])))\n",
    "    print(\"count_numbers_of_sharedcontigs took \", time.time()-s, \"seconds\")\n",
    "    return links\n",
    "\n",
    "\n",
    "def recursive_set_allneighbors(k, component_curr, components, links):\n",
    "    components[k] = component_curr\n",
    "    for l in links[k][0]:\n",
    "\n",
    "        if components[l] < 0 :\n",
    "\n",
    "            recursive_set_allneighbors(l, component_curr, components, links)\n",
    "\n",
    "\n",
    "def find_connected_components(links):\n",
    "    s = time.time()\n",
    "    K = np.shape(links)[0]\n",
    "    components = np.zeros(K).astype(int) - 1\n",
    "    component_curr = 0\n",
    "\n",
    "    for k in np.arange(K):\n",
    "\n",
    "        if components[k] < 0:\n",
    "\n",
    "            recursive_set_allneighbors(k, component_curr, components, links)\n",
    "            component_curr += 1\n",
    "\n",
    "    if (component_curr != len(set(components))):\n",
    "        raise Exception(\"problem with component calculations\")\n",
    "        exit()\n",
    "    print(\"find_connected_components took \", time.time()-s, \"seconds\")\n",
    "    num_components = component_curr\n",
    "    numclust_incomponents = np.unique(components, return_counts=True)[1]\n",
    "    print(numclust_incomponents)\n",
    "    return components, num_components, numclust_incomponents\n",
    "\n",
    "\n",
    "def merge_members_by_connnected_components(components, num_components, members):\n",
    "    K = len(components)\n",
    "    clusters = [[] for i in range(num_components)]\n",
    "\n",
    "    for k in np.arange(K):\n",
    "        clusters[components[k]].append(members[k])\n",
    " \n",
    "    # for i in np.arange(num_components):\n",
    "        # clusters[i] = np.unique(np.concatenate(clusters[i]).ravel())\n",
    "       \n",
    "    return clusters\n",
    "\n",
    "\n",
    "def cluster_by_connecting_centroids(dat, d0, min_shared_contigs):\n",
    "    s = time.time()\n",
    "    contig_names = dat.columns\n",
    "    dat = dat.to_numpy(dtype=np.float32)\n",
    "    N, C = np.shape(dat)\n",
    "\n",
    "    Rc    = dat.sum(axis=0)\n",
    "    Rn    = dat.sum(axis=1)\n",
    "    members, dists = cluster_by_centroids(dat, d0, N, C, Rc, Rn)\n",
    "    # d1 = d0 * np.sqrt(N)\n",
    "    d1 = d0 * 2\n",
    "    # d1 = d0 \n",
    "    links = count_numbers_of_sharedcontigs(dists, d1, min_shared_contigs)\n",
    "    components, num_components, numclust_incomponents = find_connected_components(links)\n",
    "    print(\"number of connected components\", num_components)\n",
    "    clusters = merge_members_by_connnected_components(components, num_components, members)\n",
    "\n",
    "    print(\"count_by_connecting_centroids took \", time.time()-s, \"seconds\")\n",
    "    return clusters, numclust_incomponents\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    s = time.time()\n",
    "    print(\"clustering initiated\"+'\\n')\n",
    "    tmp_dir = \"/big/work/metadevol/benchmark_dataset1/\"\n",
    "    # tmp_dir = \"/big/work/metadevol/scripts/bamtools_api/build/\"\n",
    "    dat = pd.read_pickle(tmp_dir + 'X_pickle')\n",
    "    d0 = 1\n",
    "    min_shared_contigs = 5\n",
    "    clusters, numclust_incomponents = cluster_by_connecting_centroids(dat, d0, min_shared_contigs)\n",
    "    print(\"overall time taken for new clustering is: \", time.time()-s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sum_t' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/big/work/metadevol/scripts/new_clustering_algorithm.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/big/work/metadevol/scripts/new_clustering_algorithm.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(sum_t, sum_m1, \u001b[39msum\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sum_t' is not defined"
     ]
    }
   ],
   "source": [
    "print(sum_t, sum_m1, sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'inds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/big/work/metadevol/scripts/new_clustering_algorithm.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/big/work/metadevol/scripts/new_clustering_algorithm.ipynb#W3sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mlen\u001b[39m(inds)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'inds' is not defined"
     ]
    }
   ],
   "source": [
    "len(inds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f, fi in zip(clusters, range(len(clusters))):\n",
    "    # f = map(str,f)\n",
    "    print(np.shape(f))\n",
    "    for q in f:\n",
    "        with open(\"/big/work/metadevol/benchmark_dataset1/\" + \"connected_components_new\", 'a') as file:\n",
    "        # with open(\"/big/work/metadevol/scripts/bamtools_api/build/\" + \"connected_components_new\", 'a') as file:\n",
    "            for r in q:\n",
    "                file.write(str(r) + \" \" + str(fi) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.min(dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.exp(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clustering initiated\n",
      "\n",
      "alpha optimized is: 8.445274503124452 and took 0.8412892818450928 seconds\n",
      "\n",
      "[65.22040543 47.1864485  45.4985623  36.14973427 17.21545533 18.43637501\n",
      " 15.80844796 16.37250452 29.39193912 20.15584564 29.15500607 28.53100593\n",
      " 20.81132077 17.49222146 18.4170369  19.5301161  31.00646485 31.11921922\n",
      " 20.18677541 21.07461887 11.55151021 18.80684603 14.16525629 13.46192623\n",
      " 51.16119628 34.48034449 52.75031566 48.47356652 15.63879727 11.84962248\n",
      " 15.98861683 14.0951357  35.04262459 29.36798715 21.2643935  21.12819982\n",
      " 17.5658027  25.39579338 18.97260361 19.17378892 27.84308525 23.76384792\n",
      " 22.5367284  30.593453   17.38873491 14.71548171 17.3165635  16.06592692\n",
      " 23.57558881 20.74808658 21.65756739 16.72561733  7.88493088 15.72649325\n",
      " 14.99322257 11.93926997 34.11144471 22.76810395 39.3396765  36.22597808\n",
      " 18.41662639 15.26751019 21.57078773 13.79935398 93.31304796 72.22852302\n",
      " 50.41925201 46.44344144 13.37765995 20.27405847 13.28663469 16.96846633\n",
      " 75.124399   60.957275   63.75756158 74.971858   15.14120478 14.58394962\n",
      " 14.78156402 18.98009788 23.73257956 26.57998879 12.43505792 17.43157732\n",
      " 10.99440912 19.15068019 12.34924951 14.48620304 34.1945133  26.01789078\n",
      " 30.87921104 33.38165947  9.67470662  9.17323096  9.1525368  10.33295129\n",
      " 20.75483167 21.76618621 13.73776389 15.8860262  13.34454611 22.10864315\n",
      " 14.91498791 19.53430338 31.54565916 28.76186132 24.75665542 38.19301418\n",
      " 10.42493173 12.96118035 12.39639325 14.9264152  18.92097981 18.80021652\n",
      " 16.96490732 14.43585859  6.15047888 14.51482775 11.61816403 10.5875416\n",
      " 30.06363908 22.40562102 32.21520256 31.53153366 17.93169613 15.87983625\n",
      " 17.62542747 13.8889938   7.54548154  5.16581804  7.97807194  5.99112584\n",
      "  2.55744616  2.90611492  4.39985752  4.20406114 12.21758417  8.72023168\n",
      " 16.44566342 17.32197783  7.11241655  5.10827524 10.85000509 10.35163086\n",
      "  5.25436378  5.44554149  4.75550138  5.09052278  2.71105016  5.25896002\n",
      "  5.18286277  5.69866171 26.46031312 18.72158193 34.98799136 32.53577759\n",
      "  7.82963689  5.84794789 11.58466609  8.85668726  7.87850001  6.97246567\n",
      "  7.04572342  6.38664948  3.99764247  4.95819463  7.91418795  6.79429155\n",
      " 14.29226757 12.60588127 14.51559853 22.0564304   5.43406192  4.35980074\n",
      "  8.5197783   7.36316642  7.62188247  7.34998083 10.89606476  7.32435304\n",
      "  2.27735077  5.22764455  8.35853251  5.5694139  19.94895102 15.0538008\n",
      " 30.1396486  30.84753708  9.997977    8.03539885 16.24064041  9.87084066\n",
      "  8.25296946  6.97416331  7.70651402  6.99114817  2.99715857  4.19965252\n",
      "  5.0495101   6.58505424  8.72055261  7.1231289  13.61841757 16.91001144\n",
      "  4.97292182  4.6286732   7.7306104  11.04188285  3.34813995  4.65927922\n",
      "  1.43504884  4.24800564  2.49120215  5.60254178  4.83593689  6.42334043\n",
      " 11.54831263  9.00316495 17.84509741 17.97517783  4.07339798  3.54108335\n",
      "  6.17396977  5.87816957  7.9777225   9.04150677  8.4596923   9.55014111\n",
      "  5.17690321  7.77465273  9.21374586 11.84183194 12.93613601 14.05459097\n",
      " 15.15437163 25.8832494   7.84678854  8.17043416 12.20139678 14.81332311\n",
      "  4.33414629  4.91689302  6.64960141  4.84190212  2.53337351  6.98769675\n",
      "  8.80525605  6.91639207 24.30184821 19.49256762 35.08421419 35.93740027\n",
      "  9.58882528  8.75823224 14.06919975  9.61194776]\n",
      "4.0801310539245605\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "# from multiprocessing import Pool\n",
    "from optimize_parameters import optimize_alpha\n",
    "from distance_calculations_gammafunction import distance\n",
    "# from distance_calculations import distance\n",
    "\n",
    "def obtain_optimized_alpha(*argv):\n",
    "    w_mat = np.array(argv[0])\n",
    "    counts = np.array(argv[1])\n",
    "    Rc = w_mat.sum(axis=0)\n",
    "    Rn = w_mat.sum(axis=1)\n",
    "    aw = optimize_alpha(w_mat, Rc, Rn, 4)\n",
    "    aw = aw * counts / counts.sum()\n",
    "    return aw\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    s = time.time()\n",
    "    print(\"clustering initiated\"+'\\n')\n",
    "    tmp_dir = \"/big/work/metadevol/benchmark_dataset1/\"\n",
    "    # tmp_dir = \"/big/work/metadevol/scripts/bamtools_api/build/\"\n",
    "    dat = pd.read_pickle(tmp_dir + 'X_pickle')\n",
    "    dat = np.array(dat)\n",
    "    N, C = np.shape(dat) \n",
    "    d0 = 1\n",
    "    min_shared_contigs = 5\n",
    "    Rc = dat.sum(axis=0)\n",
    "    Rn = dat.sum(axis=1)\n",
    "    s = time.time()\n",
    "    a     = optimize_alpha(dat, Rc, Rn, N)\n",
    "    an    = a * Rn / Rn.sum()\n",
    "    alpha = an.sum()\n",
    "    print(\"alpha optimized is:\",a, \"and took\", time.time() - s, \"seconds\\n\")\n",
    "    distr = []\n",
    "    # for c in np.arange(C):\n",
    "    #     distr.append(distance(dat[:,c], dat, Rc[c], Rc, N, an, alpha, 0))\n",
    "    #     if c == 16617:\n",
    "    #         print(distance(dat[:,c], dat, Rc[c], Rc, N, an, alpha, 0))\n",
    "\n",
    "    kmer = pd.read_csv(tmp_dir + \"kmer_counts\", header=None)\n",
    "    kmer = kmer.to_numpy()\n",
    "    tetramer_counts = kmer.reshape(45760,256)\n",
    "    tetramer_counts = (tetramer_counts / 2).transpose()\n",
    "\n",
    "    trimercountsper_nt = np.split(tetramer_counts.sum(axis=1), 64)\n",
    "\n",
    "    trimer_submatrices = np.vsplit(tetramer_counts, 64)\n",
    "    Rc_kmers = np.array(trimer_submatrices).sum(axis=1)\n",
    "    awa_values = np.array([])\n",
    "    \n",
    "    with Pool() as pool:\n",
    "        awa_values = pool.starmap(obtain_optimized_alpha, [(x, y) for x, y in zip(trimer_submatrices, trimercountsper_nt)])\n",
    "    \n",
    "    awa_values = np.array(awa_values)\n",
    "    alpha_values = awa_values.sum(axis=1)\n",
    "    awa_values = awa_values.flatten()\n",
    "    print(awa_values)\n",
    "    # dist = []\n",
    "    # for c in np.arange(np.shape(tetramer_counts)[1]):\n",
    "    #     dist.append(distance(tetramer_counts[:,c], tetramer_counts[:,c], Rc_kmer[:,c], Rc_kmer[:,c], 256, awa_values, alpha_values, 1))\n",
    "    print(time.time()-s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.0000e+00, 2.3000e+01, 1.1650e+02, ..., 5.6000e+01, 0.0000e+00,\n",
       "        2.7500e+01],\n",
       "       [0.0000e+00, 1.5000e+01, 1.1000e+02, ..., 4.5500e+01, 1.0000e+00,\n",
       "        2.2000e+01],\n",
       "       [8.5000e+00, 1.5100e+02, 5.4000e+01, ..., 3.1450e+02, 4.0000e+00,\n",
       "        5.3000e+01],\n",
       "       ...,\n",
       "       [4.9000e+01, 5.4950e+02, 2.8000e+01, ..., 5.4800e+02, 3.6500e+01,\n",
       "        7.3000e+01],\n",
       "       [1.1000e+02, 1.6135e+03, 1.0000e+00, ..., 6.0650e+02, 1.1900e+02,\n",
       "        1.4350e+02],\n",
       "       [7.2500e+01, 1.1155e+03, 5.5000e+00, ..., 5.6150e+02, 6.9000e+01,\n",
       "        5.7500e+01]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rc_kmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(np.array(distr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "3.12775078e+01,  3.47597542e+01,  2.73754501e+01,  2.89249573e+01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmer = pd.read_csv(tmp_dir + \"kmer_counts\", header=None)\n",
    "kmer = kmer.to_numpy()\n",
    "tetramer_counts = kmer.reshape(45760,256)\n",
    "tetramer_counts = (tetramer_counts / 2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(Rc_kmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "awa_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
